{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330,)\n",
      "(147,)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dropout, Concatenate, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/wohlert/keras-squeezenet/releases/download/v0.1/squeezenet_weights.h5'\n",
    "\n",
    "def _fire(x, filters, name=\"fire\"):\n",
    "    sq_filters, ex1_filters, ex2_filters = filters\n",
    "    squeeze = Convolution2D(sq_filters, (1, 1), activation='relu', padding='same', name=name + \"squeeze1x1\")(x)\n",
    "    expand1 = Convolution2D(ex1_filters, (1, 1), activation='relu', padding='same', name=name + \"expand1x1\")(squeeze)\n",
    "    expand2 = Convolution2D(ex2_filters, (3, 3), activation='relu', padding='same', name=name + \"expand3x3\")(squeeze)\n",
    "    x = Concatenate(axis=-1, name=name)([expand1, expand2])\n",
    "    return x\n",
    "\n",
    "def SqueezeNet(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=1000):\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = Convolution2D(64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name='conv1')(img_input)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (16, 64, 64), name=\"fire2\")\n",
    "    y = _fire(x, (16, 64, 64), name=\"fire3\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool3', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (32, 128, 128), name=\"fire4\")\n",
    "    y = _fire(x, (32, 128, 128), name=\"fire5\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)   \n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool5', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (48, 192, 192), name=\"fire6\")\n",
    "    y = _fire(x, (48, 192, 192), name=\"fire7\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = _fire(x, (64, 256, 256), name=\"fire8\")\n",
    "    y = _fire(x, (64, 256, 256), name=\"fire9\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dropout(0.5, name='dropout9')(x)\n",
    "\n",
    "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "        x = AveragePooling2D(pool_size=(13, 13), name='avgpool10')(x)\n",
    "        x = Flatten(name='flatten10')(x)\n",
    "        x = Activation(\"softmax\", name='softmax')(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = GlobalAveragePooling2D(name=\"avgpool10\")(x)\n",
    "        else:\n",
    "            x = GlobalMaxPooling2D(name=\"maxpool10\")(x)\n",
    "\n",
    "    model = Model(img_input, x, name=\"squeezenet\")\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        weights_path = get_file('squeezenet_weights.h5',\n",
    "                                WEIGHTS_PATH,\n",
    "                                cache_subdir='models')\n",
    "\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/cars_im/\"\n",
    "with open(\"../datasets/cars_filtered.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = int(row[3])\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(int(msrp))\n",
    "\n",
    "train_indices = np.load(\"cars_train_indices.npy\")\n",
    "test_indices = np.load(\"cars_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)\n",
    "\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "])\n",
    "\n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 4)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 4)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"25\":\n",
    "                    Y[i,:] = np.array([1,0,0,0])\n",
    "                if p == \"50\":\n",
    "                    Y[i,:] = np.array([0,1,0,0])\n",
    "                if p == \"75\":\n",
    "                    Y[i,:] = np.array([0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "#             X = seq.augment_images(X)\n",
    "            \n",
    "            yield (X, Y)\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_settings = 1\n",
    "\n",
    "hp_dropout = [0.5] * num_settings\n",
    "\n",
    "#RMSprop\n",
    "hp_lr = [0.005] * num_settings\n",
    "hp_rho = [0.9] * num_settings\n",
    "hp_epsilon = [1e-07] * num_settings\n",
    "hp_decay = [0.0] * num_settings\n",
    "\n",
    "# Number of hidden units\n",
    "hp_hidden = [256] * num_settings\n",
    "\n",
    "# Minibatch size\n",
    "hp_mbsize = [256] * num_settings\n",
    "\n",
    "num_epochs = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 55, 55, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2squeeze1x1 (Conv2D)        (None, 55, 55, 16)   1040        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2expand1x1 (Conv2D)         (None, 55, 55, 64)   1088        fire2squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2expand3x3 (Conv2D)         (None, 55, 55, 64)   9280        fire2squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2 (Concatenate)             (None, 55, 55, 128)  0           fire2expand1x1[0][0]             \n",
      "                                                                 fire2expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire3squeeze1x1 (Conv2D)        (None, 55, 55, 16)   2064        fire2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire3expand1x1 (Conv2D)         (None, 55, 55, 64)   1088        fire3squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3expand3x3 (Conv2D)         (None, 55, 55, 64)   9280        fire3squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3 (Concatenate)             (None, 55, 55, 128)  0           fire3expand1x1[0][0]             \n",
      "                                                                 fire3expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 128)  0           fire2[0][0]                      \n",
      "                                                                 fire3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 128)  512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)         (None, 27, 27, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4squeeze1x1 (Conv2D)        (None, 27, 27, 32)   4128        maxpool3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire4expand1x1 (Conv2D)         (None, 27, 27, 128)  4224        fire4squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4expand3x3 (Conv2D)         (None, 27, 27, 128)  36992       fire4squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4 (Concatenate)             (None, 27, 27, 256)  0           fire4expand1x1[0][0]             \n",
      "                                                                 fire4expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire5squeeze1x1 (Conv2D)        (None, 27, 27, 32)   8224        fire4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire5expand1x1 (Conv2D)         (None, 27, 27, 128)  4224        fire5squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5expand3x3 (Conv2D)         (None, 27, 27, 128)  36992       fire5squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5 (Concatenate)             (None, 27, 27, 256)  0           fire5expand1x1[0][0]             \n",
      "                                                                 fire5expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 27, 27, 256)  0           fire4[0][0]                      \n",
      "                                                                 fire5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 27, 27, 256)  1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "maxpool5 (MaxPooling2D)         (None, 13, 13, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6squeeze1x1 (Conv2D)        (None, 13, 13, 48)   12336       maxpool5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire6expand1x1 (Conv2D)         (None, 13, 13, 192)  9408        fire6squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6expand3x3 (Conv2D)         (None, 13, 13, 192)  83136       fire6squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6 (Concatenate)             (None, 13, 13, 384)  0           fire6expand1x1[0][0]             \n",
      "                                                                 fire6expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire7squeeze1x1 (Conv2D)        (None, 13, 13, 48)   18480       fire6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire7expand1x1 (Conv2D)         (None, 13, 13, 192)  9408        fire7squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7expand3x3 (Conv2D)         (None, 13, 13, 192)  83136       fire7squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7 (Concatenate)             (None, 13, 13, 384)  0           fire7expand1x1[0][0]             \n",
      "                                                                 fire7expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 13, 13, 384)  0           fire6[0][0]                      \n",
      "                                                                 fire7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 13, 13, 384)  1536        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire8squeeze1x1 (Conv2D)        (None, 13, 13, 64)   24640       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8expand1x1 (Conv2D)         (None, 13, 13, 256)  16640       fire8squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8expand3x3 (Conv2D)         (None, 13, 13, 256)  147712      fire8squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8 (Concatenate)             (None, 13, 13, 512)  0           fire8expand1x1[0][0]             \n",
      "                                                                 fire8expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire9squeeze1x1 (Conv2D)        (None, 13, 13, 64)   32832       fire8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire9expand1x1 (Conv2D)         (None, 13, 13, 256)  16640       fire9squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9expand3x3 (Conv2D)         (None, 13, 13, 256)  147712      fire9squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9 (Concatenate)             (None, 13, 13, 512)  0           fire9expand1x1[0][0]             \n",
      "                                                                 fire9expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 13, 512)  0           fire8[0][0]                      \n",
      "                                                                 fire9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 13, 13, 512)  2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4)            394756      batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,122,372\n",
      "Trainable params: 1,119,812\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:48: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:48: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=1, epochs=500, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    }
   ],
   "source": [
    "# store the results of each setting\n",
    "train_losses = np.zeros(num_settings)\n",
    "dev_losses = np.zeros(num_settings)\n",
    "\n",
    "for setting in range(num_settings):\n",
    "    model = SqueezeNet(include_top=True)\n",
    "    \n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Convolution2D(256, (1, 1), padding='valid', name='top_conv', input_shape=(model.layers[-1].output_shape[1:])))\n",
    "    top_model.add(AveragePooling2D(pool_size=(5, 5), name='top_avgpool'))\n",
    "    top_model.add(Flatten(input_shape=(model.layers[-1].output_shape[1:]),name='top_flatten'))\n",
    "    top_model.add(Dropout(hp_dropout[setting], name='top_dropout'))\n",
    "    top_model.add(Dense(hp_hidden[setting], activation='relu', kernel_initializer='glorot_uniform', name='top_dense'))\n",
    "    top_model.add(Dense(4, activation='softmax', name='output', kernel_initializer='glorot_uniform'))\n",
    "    \n",
    "    # add the model on top of the convolutional base\n",
    "    new_model = Model(inputs= model.input, outputs = top_model(model.layers[-1].output))\n",
    "    new_model.summary()\n",
    "\n",
    "    new_model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    checkpoint_path = 'output/cars-cnn-PriceNet-Class-Aug/{epoch:05d}.hdf5'\n",
    "    \n",
    "    # keep a checkpoint\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, period=5)\n",
    "    \n",
    "    \n",
    "    minibatch_size = hp_mbsize[setting]\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(test_indices, minibatch_size),\n",
    "        steps_per_epoch=test_steps,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        nb_val_samples=test_steps,\n",
    "        callbacks=[checkpoint])\n",
    "    \n",
    "   \n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])-\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 25 + 25\n",
    "    predicted_label.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
