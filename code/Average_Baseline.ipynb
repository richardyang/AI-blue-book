{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average baseline for bikes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the metrics for a model that only predicts the average price\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_inds = []\n",
    "im_names = []\n",
    "im_prices = np.zeros(21843)\n",
    "with open('../datasets/bikes_filtered.csv', 'r') as f:\n",
    "        datareader = csv.reader(f)\n",
    "        for i, line in enumerate(datareader):\n",
    "            im_inds.append(line[0])\n",
    "            im_names.append(line[1])\n",
    "            im_prices[i] = int(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = np.average(im_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682.3578720871676"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = np.full((21843, ), avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inds = np.load('bikes_train_indices.npy')\n",
    "test_inds = np.load('bikes_test_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = predicted[test_inds]\n",
    "im_prices = im_prices[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3276787.7276074942"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(im_prices, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1318.5307114396887"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(im_prices, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00016387045703925018"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(im_prices, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average baseline for cars dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_inds = []\n",
    "im_names = []\n",
    "im_prices = np.zeros(1478)\n",
    "with open('../datasets/cars_filtered.csv', 'r') as f:\n",
    "        datareader = csv.reader(f)\n",
    "        for i, line in enumerate(datareader):\n",
    "            im_inds.append(line[0])\n",
    "            im_names.append(line[1])\n",
    "            im_prices[i] = int(line[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = np.average(im_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60885.625845737486"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = np.full((1478, ), avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inds = np.load('cars_train_indices.npy')\n",
    "test_inds = np.load('cars_test_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = predicted[test_inds]\n",
    "im_prices = im_prices[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5812600017.6289692"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(im_prices, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44410.57105575654"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(im_prices, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.0765636178981026e-07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(im_prices, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Average baselines for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../datasets/bikes_im/\"\n",
    "\n",
    "im_inds = []\n",
    "im_names = []\n",
    "im_prices = []\n",
    "im_labels = []\n",
    "with open('../datasets/bikes_classified.csv', 'r') as f:\n",
    "        datareader = csv.reader(f)\n",
    "        for line in datareader:\n",
    "            im_inds.append(line[0])\n",
    "            im_names.append(line[1])\n",
    "            im_prices.append(line[2])\n",
    "            im_labels.append(line[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "# Use same train-test split as other models\n",
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate random classes out of '25', '50', '75'\n",
    "labels = np.array(im_labels)\n",
    "labels_test = labels[test_indices]\n",
    "predictions = np.random.choice(['25', '50', '75'], 2185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.00      0.00      0.00       496\n",
      "         25       0.27      0.33      0.30       596\n",
      "         50       0.26      0.33      0.29       563\n",
      "         75       0.23      0.32      0.27       530\n",
      "\n",
      "avg / total       0.20      0.25      0.22      2185\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  0 150 170 176]\n",
      " [  0 198 195 203]\n",
      " [  0 187 184 192]\n",
      " [  0 192 168 170]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenchen/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (metrics.classification_report(labels_test, predictions)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../datasets/cars_im/\"\n",
    "\n",
    "im_inds = []\n",
    "im_names = []\n",
    "im_prices = []\n",
    "im_labels = []\n",
    "with open('../datasets/cars_classified.csv', 'r') as f:\n",
    "        datareader = csv.reader(f)\n",
    "        for line in datareader:\n",
    "            im_inds.append(line[0])\n",
    "            im_names.append(line[2])\n",
    "            im_prices.append(line[3])\n",
    "            im_labels.append(line[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330,)\n",
      "(147,)\n"
     ]
    }
   ],
   "source": [
    "# Use same train-test split as other models\n",
    "train_indices = np.load(\"cars_train_indices.npy\")\n",
    "test_indices = np.load(\"cars_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate random classes out of '25', '50', '75'\n",
    "labels = np.array(im_labels)\n",
    "labels_test = labels[test_indices]\n",
    "predictions = np.random.choice(['20', '40', '60', '80'], 147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.00      0.00      0.00        29\n",
      "         20       0.38      0.39      0.38        36\n",
      "         40       0.19      0.21      0.20        34\n",
      "         60       0.14      0.20      0.16        25\n",
      "         80       0.14      0.22      0.17        23\n",
      "\n",
      "avg / total       0.18      0.21      0.19       147\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 0  5 12  7  5]\n",
      " [ 0 14  5 10  7]\n",
      " [ 0  9  7 10  8]\n",
      " [ 0  3  5  5 12]\n",
      " [ 0  6  8  4  5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenchen/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (metrics.classification_report(labels_test, predictions)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
