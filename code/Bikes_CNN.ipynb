{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "07OhpBLDqTIf"
   },
   "source": [
    "# The Price Is Right: Predicting Prices with Product Images\n",
    "\n",
    "### Milestone Report\n",
    "\n",
    "------------\n",
    "\n",
    "**Steven Chen, Edward Chou, Richard Yang**\n",
    "\n",
    "(Edward Chou and Richard Yang are not part of 230, but are part of 229.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages\n",
    "\n",
    "---------------\n",
    "\n",
    "For this project, we choose to use Keras with a Tensorflow backend. Keras is well suited for building complex CNNs, and we have experience with both Tensorflow and Keras from the CS230 programming assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m5WvbQev1OuM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the VGG-16 network without the final (top) layer, using the learned ImageNet weights. VGG-16 is a very deep CNN trained for object recognition on the ImageNet challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "hp_dropout = 0.2\n",
    "\n",
    "#RMSprop\n",
    "hp_lr = 0.01\n",
    "hp_rho = 0.9 #RMSprop\n",
    "hp_epsilon = 1e-07\n",
    "hp_decay = 0.0\n",
    "\n",
    "# Number of hidden units\n",
    "hp_hidden = 256\n",
    "\n",
    "# Minibatch size\n",
    "hp_mbsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LXDZTeHL1RRc"
   },
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our own layer on top of VGG. In particular, we flatten the final feature mapping of VGG-16 (consisting of 512 7 by 7 filters) into a single dimension. We then add a fully connected layer of 256 hidden units with ReLU activations, and use uniform Xavier initialization.\n",
    "\n",
    "We finish our model with an output layer of a single linear activation neuron, which will output the predicted price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sQa_EjD81S0_"
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=(model.output_shape[1:])))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "# We do random weight intialization\n",
    "top_model.add(Dropout(hp_dropout))\n",
    "top_model.add(Dense(hp_hidden, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "top_model.add(Dense(1, activation='linear', name='output', kernel_initializer='glorot_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the pretrained VGG layers to be non-trainable so that we do spend time learning them. Instead, our learning will focus on the new layers we have added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PIa-BP_J1jrM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 6423041   \n",
      "=================================================================\n",
      "Total params: 21,137,729\n",
      "Trainable params: 6,423,041\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add the model on top of the convolutional base\n",
    "new_model = Model(inputs= model.input, outputs = top_model(model.output))\n",
    "\n",
    "# set the first 19 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see our added layer as sequential_2. Only our new layer is trainable: the rest are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model using mean squared error as the loss (since we are performing regression), and use an RMSprop optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YrdQv9kyEpH-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# SGD\n",
    "#new_model.compile(loss='mean_squared_error',\n",
    "#              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "# RMSprop\n",
    "new_model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizers.RMSprop(lr=hp_lr, rho=hp_rho, epsilon=hp_epsilon, decay=hp_decay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the great Keras ImageDataGenerator to process our images. We rescale the image colors to be between 0 and 1, then perform mean subtraction on each image channel, in order to help our images be more standardized and similar to images the VGG network has seen before.\n",
    "\n",
    "Our dataset relies on the bike images and the price csv to be in the root directory, because that is where FloydHub puts them. As of now, we read in the images into a large numpy array, then feed this into the network. We hit memory issues when trying to load all 20000 plus images, so for now we load a smaller subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"../datasets/bikes_filtered.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(int(msrp))\n",
    "\n",
    "        \n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 1))\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 1))\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)                \n",
    "                Y[i] = prices[index]\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19658\n",
      "2185\n"
     ]
    }
   ],
   "source": [
    "# create random permutation of number of data points, then cut\n",
    "# into train/test split\n",
    "\n",
    "# we have 21843 bike images total.\n",
    "dataset_indices = np.random.permutation(21843)\n",
    "\n",
    "# 90% train, 10% test\n",
    "cutoff = int(len(dataset_indices) * 0.9)\n",
    "train_indices = dataset_indices[:cutoff]\n",
    "test_indices = dataset_indices[cutoff:]\n",
    "\n",
    "print(len(train_indices))\n",
    "print(len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=308, epochs=30, validation_steps=35)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 118s 383ms/step - loss: 3444640.1684 - val_loss: 794131.5982\n",
      "Epoch 2/30\n",
      "308/308 [==============================] - 113s 367ms/step - loss: 961566.9926 - val_loss: 679975.8656\n",
      "Epoch 3/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 786348.9703 - val_loss: 818272.5634\n",
      "Epoch 4/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 679636.9538 - val_loss: 706613.3424\n",
      "Epoch 5/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 608571.9162 - val_loss: 635050.9807\n",
      "Epoch 6/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 569308.1362 - val_loss: 620818.0041\n",
      "Epoch 7/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 537819.8490 - val_loss: 615721.7528\n",
      "Epoch 8/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 494967.1216 - val_loss: 808077.3225\n",
      "Epoch 9/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 476864.2437 - val_loss: 614537.4018\n",
      "Epoch 10/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 445464.0957 - val_loss: 585973.9857\n",
      "Epoch 11/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 419283.0707 - val_loss: 597664.6357\n",
      "Epoch 12/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 408513.4275 - val_loss: 637876.3681\n",
      "Epoch 13/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 382808.7064 - val_loss: 836015.0479\n",
      "Epoch 14/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 369664.1064 - val_loss: 711062.6733\n",
      "Epoch 15/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 350935.7737 - val_loss: 611820.7492\n",
      "Epoch 16/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 340253.2581 - val_loss: 666941.0888\n",
      "Epoch 17/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 349378.5221 - val_loss: 632202.3806\n",
      "Epoch 18/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 326755.0964 - val_loss: 577853.2425\n",
      "Epoch 19/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 316417.2940 - val_loss: 777416.9597\n",
      "Epoch 20/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 307447.9113 - val_loss: 805282.8319\n",
      "Epoch 21/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 300620.8656 - val_loss: 556938.9536\n",
      "Epoch 22/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 292092.8609 - val_loss: 589337.5065\n",
      "Epoch 23/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 289437.4228 - val_loss: 647636.4823\n",
      "Epoch 24/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 279376.8625 - val_loss: 574904.3021\n",
      "Epoch 25/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 283993.5011 - val_loss: 635339.0830\n",
      "Epoch 26/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 273330.1226 - val_loss: 589467.2853\n",
      "Epoch 27/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 264255.5210 - val_loss: 559718.2155\n",
      "Epoch 28/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 261401.6339 - val_loss: 596603.8202\n",
      "Epoch 29/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 259537.4060 - val_loss: 626419.1724\n",
      "Epoch 30/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 252873.7165 - val_loss: 535399.8666\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "minibatch_size = hp_mbsize\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a data point and run it through the neural network\n",
    "# Return the predicted value and calculate the MSE\n",
    "def evaluate(index):\n",
    "    msrp = prices[index]\n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    prediction = new_model.predict(data, msrp)\n",
    "    #prediction = new_model.predict(data, np.expand_dims(np.array(msrp), axis=0))\n",
    "    #print(\"Bike index: \" + str(index))\n",
    "    #print(\"Actual price: \" + str(msrp))\n",
    "    #print(\"Predicted price: \" + str(prediction))\n",
    "    mse = (prediction-msrp)**2\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(21843):\n",
    "    error.append(evaluate(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26967e+06\n"
     ]
    }
   ],
   "source": [
    "# TODO: Record hyperparameters and average MSE\n",
    "print(np.mean(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEWCAYAAADPZygPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7ea92a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "CNN_transfer.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
