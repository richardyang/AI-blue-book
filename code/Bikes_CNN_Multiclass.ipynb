{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "x = model.output\n",
    "x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = Dense(4, activation='softmax', name='output', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "# add new classifier model on top of convolutional base\n",
    "new_model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 19 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 21,138,500\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SGD and Categorical CE Loss\n",
    "#sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# RMSprop\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"bikes_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        label = row[3]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 4)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 4)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"25\":\n",
    "                    Y[i,:] = np.array([1,0,0,0])\n",
    "                if p == \"50\":\n",
    "                    Y[i,:] = np.array([0,1,0,0])\n",
    "                if p == \"75\":\n",
    "                    Y[i,:] = np.array([0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=308, epochs=7, validation_data=<generator..., validation_steps=35)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 260s - loss: 8.1458 - acc: 0.4724 - val_loss: 6.7911 - val_acc: 0.5482\n",
      "Epoch 2/7\n",
      "308/308 [==============================] - 244s - loss: 6.7782 - acc: 0.5441 - val_loss: 6.7387 - val_acc: 0.5456\n",
      "Epoch 3/7\n",
      "308/308 [==============================] - 244s - loss: 6.0370 - acc: 0.5738 - val_loss: 5.3828 - val_acc: 0.5976\n",
      "Epoch 4/7\n",
      "308/308 [==============================] - 244s - loss: 4.2859 - acc: 0.6043 - val_loss: 1.0118 - val_acc: 0.6904\n",
      "Epoch 5/7\n",
      "308/308 [==============================] - 244s - loss: 0.9698 - acc: 0.6942 - val_loss: 0.7514 - val_acc: 0.7190\n",
      "Epoch 6/7\n",
      "308/308 [==============================] - 244s - loss: 0.7018 - acc: 0.7526 - val_loss: 0.7405 - val_acc: 0.7390\n",
      "Epoch 7/7\n",
      "308/308 [==============================] - 244s - loss: 0.6248 - acc: 0.7785 - val_loss: 0.7428 - val_acc: 0.7590\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "minibatch_size = 64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=308, epochs=7, validation_data=<generator..., validation_steps=35)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "308/308 [==============================] - 243s - loss: 0.5658 - acc: 0.8001 - val_loss: 0.6909 - val_acc: 0.7728\n",
      "Epoch 2/7\n",
      "308/308 [==============================] - 244s - loss: 0.5195 - acc: 0.8182 - val_loss: 0.6896 - val_acc: 0.7892\n",
      "Epoch 3/7\n",
      "308/308 [==============================] - 244s - loss: 0.4793 - acc: 0.8356 - val_loss: 0.7018 - val_acc: 0.7852\n",
      "Epoch 4/7\n",
      "308/308 [==============================] - 244s - loss: 0.4491 - acc: 0.8532 - val_loss: 0.7078 - val_acc: 0.7941\n",
      "Epoch 5/7\n",
      "308/308 [==============================] - 244s - loss: 0.4233 - acc: 0.8590 - val_loss: 0.6998 - val_acc: 0.8039\n",
      "Epoch 6/7\n",
      "308/308 [==============================] - 244s - loss: 0.3925 - acc: 0.8696 - val_loss: 0.7438 - val_acc: 0.7768\n",
      "Epoch 7/7\n",
      "308/308 [==============================] - 243s - loss: 0.3727 - acc: 0.8794 - val_loss: 0.7724 - val_acc: 0.8021\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('bikes_classification_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
