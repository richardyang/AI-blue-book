{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "x = model.output\n",
    "x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = Dense(4, activation='softmax', name='output', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "# add new classifier model on top of convolutional base\n",
    "new_model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 19 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 21,138,500\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SGD and Categorical CE Loss\n",
    "#sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# RMSprop\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"../datasets/bikes_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        label = row[3]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 4)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 4)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"25\":\n",
    "                    Y[i,:] = np.array([1,0,0,0])\n",
    "                if p == \"50\":\n",
    "                    Y[i,:] = np.array([0,1,0,0])\n",
    "                if p == \"75\":\n",
    "                    Y[i,:] = np.array([0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=30, validation_steps=35, validation_data=<generator..., steps_per_epoch=308)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "308/308 [==============================] - 119s 385ms/step - loss: 7.8333 - acc: 0.4911 - val_loss: 5.7868 - val_acc: 0.6052\n",
      "Epoch 2/30\n",
      "308/308 [==============================] - 114s 369ms/step - loss: 5.9280 - acc: 0.5972 - val_loss: 5.4599 - val_acc: 0.6265\n",
      "Epoch 3/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 4.0038 - acc: 0.6583 - val_loss: 2.6652 - val_acc: 0.6621\n",
      "Epoch 4/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 1.5646 - acc: 0.6944 - val_loss: 0.9285 - val_acc: 0.7179\n",
      "Epoch 5/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.8520 - acc: 0.7259 - val_loss: 0.7749 - val_acc: 0.7381\n",
      "Epoch 6/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.6716 - acc: 0.7625 - val_loss: 0.7098 - val_acc: 0.7457\n",
      "Epoch 7/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.5742 - acc: 0.7896 - val_loss: 0.7226 - val_acc: 0.7608\n",
      "Epoch 8/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.5155 - acc: 0.8124 - val_loss: 0.7115 - val_acc: 0.7772\n",
      "Epoch 9/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 0.4746 - acc: 0.8295 - val_loss: 0.7352 - val_acc: 0.7723\n",
      "Epoch 10/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.4406 - acc: 0.8411 - val_loss: 0.8825 - val_acc: 0.7421\n",
      "Epoch 11/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.4076 - acc: 0.8574 - val_loss: 0.7551 - val_acc: 0.7870\n",
      "Epoch 12/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.3733 - acc: 0.8674 - val_loss: 0.7619 - val_acc: 0.7959\n",
      "Epoch 13/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.3520 - acc: 0.8785 - val_loss: 0.7705 - val_acc: 0.7892\n",
      "Epoch 14/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.3271 - acc: 0.8877 - val_loss: 0.7831 - val_acc: 0.7955\n",
      "Epoch 15/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.3213 - acc: 0.8910 - val_loss: 0.8513 - val_acc: 0.7950\n",
      "Epoch 16/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2968 - acc: 0.8985 - val_loss: 0.8448 - val_acc: 0.7870\n",
      "Epoch 17/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2822 - acc: 0.9069 - val_loss: 0.8924 - val_acc: 0.7928\n",
      "Epoch 18/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2688 - acc: 0.9131 - val_loss: 0.8375 - val_acc: 0.8061\n",
      "Epoch 19/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2603 - acc: 0.9187 - val_loss: 0.8717 - val_acc: 0.8119\n",
      "Epoch 20/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2426 - acc: 0.9228 - val_loss: 0.9111 - val_acc: 0.8021\n",
      "Epoch 21/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2358 - acc: 0.9258 - val_loss: 0.9389 - val_acc: 0.8088\n",
      "Epoch 22/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 0.2289 - acc: 0.9283 - val_loss: 0.9119 - val_acc: 0.8052\n",
      "Epoch 23/30\n",
      "308/308 [==============================] - 114s 370ms/step - loss: 0.2150 - acc: 0.9340 - val_loss: 0.9473 - val_acc: 0.8097\n",
      "Epoch 24/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.2083 - acc: 0.9381 - val_loss: 0.8967 - val_acc: 0.8239\n",
      "Epoch 25/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.1964 - acc: 0.9419 - val_loss: 0.9209 - val_acc: 0.8221\n",
      "Epoch 26/30\n",
      "308/308 [==============================] - 114s 372ms/step - loss: 0.1858 - acc: 0.9464 - val_loss: 0.9778 - val_acc: 0.8257\n",
      "Epoch 27/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.1864 - acc: 0.9453 - val_loss: 1.0148 - val_acc: 0.8146\n",
      "Epoch 28/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.1816 - acc: 0.9495 - val_loss: 0.9564 - val_acc: 0.8217\n",
      "Epoch 29/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.1682 - acc: 0.9527 - val_loss: 1.0116 - val_acc: 0.8181\n",
      "Epoch 30/30\n",
      "308/308 [==============================] - 114s 371ms/step - loss: 0.1673 - acc: 0.9546 - val_loss: 1.0221 - val_acc: 0.8159\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "minibatch_size = 64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps)\n",
    "\n",
    "new_model.save('bikes_classification_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('../datasets/bikes_classification_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 25 + 25\n",
    "    predicted_label.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.77      0.82      0.80       496\n",
      "         25       0.79      0.92      0.85       596\n",
      "         50       0.73      0.64      0.68       563\n",
      "         75       0.68      0.59      0.63       530\n",
      "\n",
      "avg / total       0.74      0.75      0.74      2185\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[409   6   4  77]\n",
      " [  0 550  40   6]\n",
      " [ 11 126 360  66]\n",
      " [109  16  92 313]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
