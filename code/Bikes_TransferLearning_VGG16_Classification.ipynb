{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "x = model.output\n",
    "x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = Dense(4, activation='softmax', name='output', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "# add new classifier model on top of convolutional base\n",
    "new_model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 19 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 21,138,500\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SGD and Categorical CE Loss\n",
    "#sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# RMSprop\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"../datasets/bikes_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        label = row[3]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 4)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 4)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"25\":\n",
    "                    Y[i,:] = np.array([1,0,0,0])\n",
    "                if p == \"50\":\n",
    "                    Y[i,:] = np.array([0,1,0,0])\n",
    "                if p == \"75\":\n",
    "                    Y[i,:] = np.array([0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_steps=35, validation_data=<generator..., epochs=25, steps_per_epoch=35, callbacks=[<keras.ca...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "35/35 [==============================] - 19s 557ms/step - loss: 8.1949 - acc: 0.4312 - val_loss: 6.5812 - val_acc: 0.5104\n",
      "Epoch 2/25\n",
      "35/35 [==============================] - 19s 529ms/step - loss: 6.1901 - acc: 0.5425 - val_loss: 4.3833 - val_acc: 0.6381\n",
      "Epoch 3/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 5.0377 - acc: 0.6056 - val_loss: 6.7617 - val_acc: 0.5064\n",
      "Epoch 4/25\n",
      "35/35 [==============================] - 19s 552ms/step - loss: 4.6777 - acc: 0.6332 - val_loss: 3.2073 - val_acc: 0.7190\n",
      "Epoch 5/25\n",
      "35/35 [==============================] - 19s 550ms/step - loss: 3.9990 - acc: 0.6748 - val_loss: 2.6162 - val_acc: 0.7799\n",
      "Epoch 6/25\n",
      "35/35 [==============================] - 19s 557ms/step - loss: 3.6129 - acc: 0.7023 - val_loss: 2.7795 - val_acc: 0.7550\n",
      "Epoch 7/25\n",
      "35/35 [==============================] - 19s 550ms/step - loss: 3.2043 - acc: 0.7214 - val_loss: 3.0932 - val_acc: 0.7359\n",
      "Epoch 8/25\n",
      "35/35 [==============================] - 19s 551ms/step - loss: 2.9126 - acc: 0.7442 - val_loss: 2.4850 - val_acc: 0.7861\n",
      "Epoch 9/25\n",
      "35/35 [==============================] - 19s 538ms/step - loss: 2.3747 - acc: 0.7718 - val_loss: 1.5866 - val_acc: 0.8439\n",
      "Epoch 10/25\n",
      "35/35 [==============================] - 19s 547ms/step - loss: 2.2172 - acc: 0.7938 - val_loss: 2.1952 - val_acc: 0.7772\n",
      "Epoch 11/25\n",
      "35/35 [==============================] - 19s 547ms/step - loss: 2.1539 - acc: 0.8001 - val_loss: 1.6395 - val_acc: 0.8395\n",
      "Epoch 12/25\n",
      "35/35 [==============================] - 19s 550ms/step - loss: 1.8668 - acc: 0.8169 - val_loss: 1.1302 - val_acc: 0.8795\n",
      "Epoch 13/25\n",
      "35/35 [==============================] - 19s 545ms/step - loss: 1.7549 - acc: 0.8202 - val_loss: 0.9336 - val_acc: 0.9088\n",
      "Epoch 14/25\n",
      "35/35 [==============================] - 19s 535ms/step - loss: 1.5249 - acc: 0.8444 - val_loss: 0.8740 - val_acc: 0.9071\n",
      "Epoch 15/25\n",
      "35/35 [==============================] - 19s 531ms/step - loss: 1.5872 - acc: 0.8341 - val_loss: 0.7927 - val_acc: 0.9120\n",
      "Epoch 16/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 1.3717 - acc: 0.8518 - val_loss: 1.3127 - val_acc: 0.8524\n",
      "Epoch 17/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 1.2848 - acc: 0.8594 - val_loss: 0.5863 - val_acc: 0.9386\n",
      "Epoch 18/25\n",
      "35/35 [==============================] - 19s 531ms/step - loss: 1.0631 - acc: 0.8762 - val_loss: 1.7822 - val_acc: 0.7999\n",
      "Epoch 19/25\n",
      "35/35 [==============================] - 19s 531ms/step - loss: 1.1506 - acc: 0.8715 - val_loss: 0.8013 - val_acc: 0.9071\n",
      "Epoch 20/25\n",
      "35/35 [==============================] - 19s 532ms/step - loss: 1.0856 - acc: 0.8856 - val_loss: 0.8381 - val_acc: 0.9066\n",
      "Epoch 21/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 0.9640 - acc: 0.8958 - val_loss: 1.1952 - val_acc: 0.8533\n",
      "Epoch 22/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 0.8235 - acc: 0.8994 - val_loss: 0.4624 - val_acc: 0.9484\n",
      "Epoch 23/25\n",
      "35/35 [==============================] - 19s 529ms/step - loss: 0.9578 - acc: 0.8948 - val_loss: 1.5604 - val_acc: 0.8435\n",
      "Epoch 24/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 0.7644 - acc: 0.9174 - val_loss: 0.7019 - val_acc: 0.9151\n",
      "Epoch 25/25\n",
      "35/35 [==============================] - 19s 530ms/step - loss: 0.7927 - acc: 0.9096 - val_loss: 0.5902 - val_acc: 0.9289\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "num_epochs = 100\n",
    "minibatch_size = 64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "checkpoint_path = 'E:/output/bikes-cnn-VGG16-Class/{epoch:05d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, period=5)\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=25,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps,\n",
    "    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('../datasets/bikes_classification_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 25 + 25\n",
    "    predicted_label.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.79      0.99      0.88       496\n",
      "         25       0.92      0.97      0.95       596\n",
      "         50       0.95      0.82      0.88       563\n",
      "         75       0.90      0.75      0.82       530\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2185\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[490   0   1   5]\n",
      " [  2 578  12   4]\n",
      " [ 23  39 464  37]\n",
      " [109   9  12 400]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330,)\n",
      "(147,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:134: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Richard\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:134: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., callbacks=[<keras.ca..., epochs=10, validation_steps=3, validation_data=<generator..., steps_per_epoch=3)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 8.5170 - acc: 0.3146 - val_loss: 5.5877 - val_acc: 0.4787\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 2s 649ms/step - loss: 7.6064 - acc: 0.3767 - val_loss: 7.4784 - val_acc: 0.4783\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 6.6348 - acc: 0.5143 - val_loss: 4.5015 - val_acc: 0.6066\n",
      "Epoch 4/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.7735 - acc: 0.5783"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "x = model.output\n",
    "x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='glorot_normal')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='glorot_normal')(x)\n",
    "x = Dense(5, activation='softmax', name='output', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "# add new classifier model on top of convolutional base\n",
    "new_model = Model(model.input, x)\n",
    "\n",
    "# set the first 19 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Use SGD and Categorical CE Loss\n",
    "#sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.0003), metrics=['accuracy'])\n",
    "\n",
    "# RMSprop\n",
    "# new_model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/cars_im/\"\n",
    "with open(\"../datasets/cars_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[3]\n",
    "        label = row[4]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))\n",
    "        \n",
    "        \n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 5)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 5)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"20\":\n",
    "                    Y[i,:] = np.array([1,0,0,0,0])\n",
    "                if p == \"40\":\n",
    "                    Y[i,:] = np.array([0,1,0,0,0])\n",
    "                if p == \"60\":\n",
    "                    Y[i,:] = np.array([0,0,1,0,0])\n",
    "                if p == \"80\":\n",
    "                    Y[i,:] = np.array([0,0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)\n",
    "            \n",
    "train_indices = np.load(\"cars_train_indices.npy\")\n",
    "test_indices = np.load(\"cars_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)\n",
    "\n",
    "epochs = 10\n",
    "minibatch_size = 64\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "checkpoint = ModelCheckpoint('E:/output/cars-cnn-VGG16-Class/{epoch:05d}.hdf5', period=5)\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(test_indices, minibatch_size),\n",
    "    steps_per_epoch=test_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps,\n",
    "    callbacks=[checkpoint])\n",
    "# new_model.save('cars_classification_best.hdf5')\n",
    "\n",
    "\n",
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    data = preprocess_input(data)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 20 + 20\n",
    "    predicted_label.append(str(label))\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
