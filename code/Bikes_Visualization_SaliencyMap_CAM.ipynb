{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import activations\n",
    "from keras.applications import VGG16\n",
    "from keras.models import load_model\n",
    "from vis.utils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the model that we tuned. We can print out the summary of our model to double-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 21,138,500\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load our model\n",
    "model = load_model('bikes_classification_best.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to lose track of which layer we're visualizing, but we can find the ID of the layer from its name. We'll be visualizing the softmax output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "layer_name = 'output'\n",
    "layer_idx = utils.find_layer_idx(model, layer_name)\n",
    "print(layer_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for these visualization methods to work, we have to convert the softmax activations to linear activations. This code does that, and stores the new model temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "\n",
    "# Taken from vis package's util file and modified to work with Windows directory structure\n",
    "def apply_modifications(model):\n",
    "    \"\"\"Applies modifications to the model layers to create a new Graph. For example, simply changing\n",
    "    `model.layers[idx].activation = new activation` does not change the graph. The entire graph needs to be updated\n",
    "    with modified inbound and outbound tensors because of change in layer building function.\n",
    "\n",
    "    Args:\n",
    "        model: The `keras.models.Model` instance.\n",
    "\n",
    "    Returns:\n",
    "        The modified model with changes applied. Does not mutate the original `model`.\n",
    "    \"\"\"\n",
    "    # The strategy is to save the modified model and load it back. This is done because setting the activation\n",
    "    # in a Keras layer doesnt actually change the graph. We have to iterate the entire graph and change the\n",
    "    # layer inbound and outbound nodes with modified tensors. This is doubly complicated in Keras 2.x since\n",
    "    # multiple inbound and outbound nodes are allowed with the Graph API.\n",
    "    model_path = 'C:/Users/Richard/AppData/Local/Temp/temp.h5'\n",
    "    try:\n",
    "        model.save(model_path)\n",
    "        return load_model(model_path)\n",
    "    finally:\n",
    "        os.remove(model_path)\n",
    "        \n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = apply_modifications(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize saliency map and CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll load some of the examples to visualize. These are the examples we use for our final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from vis.visualization import visualize_saliency, visualize_cam, overlay\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "# A demo image from each class\n",
    "# Original images, IDs: 67, 13855, 14987, 25183, 28869, 41129, 64968, 67781\n",
    "indices = [\"67\", \"371\", \"372\", \"1813\", \"7716\", \"13855\", \"14987\", \"25183\", \"28869\", \"41129\", \"64968\", \"67781\"]\n",
    "imgs = []\n",
    "for c in indices:\n",
    "    img = utils.load_img('../datasets/visualization/bikesdemo/'+c+\".jpg\")\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each image, we'll generate the saliency map for each of the classification output classes, and plot it next to the original input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(indices)):\n",
    "    c = imgs[j]\n",
    "    for i in range(4):\n",
    "        plt.figure()\n",
    "        grads = visualize_saliency(model, layer_idx, filter_indices=i, seed_input=c, backprop_modifier='guided')\n",
    "        stitched = utils.stitch_images([c,grads], margin=0)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(stitched)\n",
    "        plt.savefig(\"../datasets/visualization/bikesdemo/saliency/\"+indices[j]+\"_\"+str(i)+\".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the same process for CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "for j in range(len(indices)):\n",
    "    c = imgs[j]\n",
    "    for i in range(4):\n",
    "        plt.figure()\n",
    "        grads = visualize_cam(model, layer_idx, filter_indices=i, seed_input=c, backprop_modifier='guided')        \n",
    "        # Create heatmap and overlay it on the original pic  \n",
    "        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(overlay(jet_heatmap[:,:,:,0], c))\n",
    "        plt.savefig(\"../datasets/visualization/bikesdemo/cam/\"+indices[j]+\"_\"+str(i)+\".png\")\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
