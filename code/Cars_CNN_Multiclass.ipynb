{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "x = model.output\n",
    "x = Flatten(input_shape=(model.output_shape[1:]))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='glorot_normal')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(300, activation='relu', kernel_initializer='glorot_normal')(x)\n",
    "x = Dense(5, activation='softmax', name='output', kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "# add new classifier model on top of convolutional base\n",
    "new_model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 19 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               7526700   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 1505      \n",
      "=================================================================\n",
      "Total params: 22,333,193\n",
      "Trainable params: 7,618,505\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use SGD and Categorical CE Loss\n",
    "#sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.0003), metrics=['accuracy'])\n",
    "\n",
    "# RMSprop\n",
    "# new_model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/cars_im/\"\n",
    "with open(\"../datasets/cars_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[3]\n",
    "        label = row[4]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'80'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 5)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 5)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"20\":\n",
    "                    Y[i,:] = np.array([1,0,0,0,0])\n",
    "                if p == \"40\":\n",
    "                    Y[i,:] = np.array([0,1,0,0,0])\n",
    "                if p == \"60\":\n",
    "                    Y[i,:] = np.array([0,0,1,0,0])\n",
    "                if p == \"80\":\n",
    "                    Y[i,:] = np.array([0,0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330,)\n",
      "(147,)\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.load(\"cars_train_indices.npy\")\n",
    "test_indices = np.load(\"cars_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=19, epochs=25, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=3)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 6.5364 - acc: 0.3540Epoch 00000: val_acc improved from -inf to 0.48387, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 6.4587 - acc: 0.3549 - val_loss: 3.7953 - val_acc: 0.4839\n",
      "Epoch 2/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 3.2822 - acc: 0.4746Epoch 00001: val_acc improved from 0.48387 to 0.54464, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 3.2224 - acc: 0.4699 - val_loss: 1.2271 - val_acc: 0.5446\n",
      "Epoch 3/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.4116 - acc: 0.5175Epoch 00002: val_acc improved from 0.54464 to 0.63134, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 1.3951 - acc: 0.5188 - val_loss: 0.9803 - val_acc: 0.6313\n",
      "Epoch 4/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 1.0543 - acc: 0.5841Epoch 00003: val_acc improved from 0.63134 to 0.70536, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 1.0565 - acc: 0.5842 - val_loss: 0.8646 - val_acc: 0.7054\n",
      "Epoch 5/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9636 - acc: 0.6119Epoch 00004: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.9669 - acc: 0.6105 - val_loss: 0.7698 - val_acc: 0.7051\n",
      "Epoch 6/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.9101 - acc: 0.6310Epoch 00005: val_acc improved from 0.70536 to 0.72321, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.9092 - acc: 0.6278 - val_loss: 0.7694 - val_acc: 0.7232\n",
      "Epoch 7/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8730 - acc: 0.6532Epoch 00006: val_acc improved from 0.72321 to 0.72350, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.8782 - acc: 0.6489 - val_loss: 0.6752 - val_acc: 0.7235\n",
      "Epoch 8/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.8156 - acc: 0.6627Epoch 00007: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.8321 - acc: 0.6571 - val_loss: 0.6482 - val_acc: 0.7188\n",
      "Epoch 9/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7693 - acc: 0.6841Epoch 00008: val_acc improved from 0.72350 to 0.74654, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.7677 - acc: 0.6820 - val_loss: 0.6736 - val_acc: 0.7465\n",
      "Epoch 10/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7511 - acc: 0.6817Epoch 00009: val_acc improved from 0.74654 to 0.75000, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.7574 - acc: 0.6820 - val_loss: 0.7523 - val_acc: 0.7500\n",
      "Epoch 11/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7193 - acc: 0.7111Epoch 00010: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.7186 - acc: 0.7083 - val_loss: 0.7078 - val_acc: 0.7327\n",
      "Epoch 12/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7122 - acc: 0.7056Epoch 00011: val_acc improved from 0.75000 to 0.78571, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.7135 - acc: 0.7053 - val_loss: 0.6273 - val_acc: 0.7857\n",
      "Epoch 13/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7115 - acc: 0.7056Epoch 00012: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.7146 - acc: 0.7030 - val_loss: 0.6972 - val_acc: 0.7650\n",
      "Epoch 14/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.7124 - acc: 0.7190Epoch 00013: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.7214 - acc: 0.7120 - val_loss: 0.6575 - val_acc: 0.7857\n",
      "Epoch 15/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6425 - acc: 0.7381Epoch 00014: val_acc improved from 0.78571 to 0.78802, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.6465 - acc: 0.7338 - val_loss: 0.6093 - val_acc: 0.7880\n",
      "Epoch 16/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6244 - acc: 0.7532Epoch 00015: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.6333 - acc: 0.7398 - val_loss: 0.5512 - val_acc: 0.7768\n",
      "Epoch 17/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6216 - acc: 0.7437Epoch 00016: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.6292 - acc: 0.7421 - val_loss: 0.6029 - val_acc: 0.7650\n",
      "Epoch 18/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5931 - acc: 0.7468Epoch 00017: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.5933 - acc: 0.7444 - val_loss: 0.6012 - val_acc: 0.7589\n",
      "Epoch 19/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.6020 - acc: 0.7302Epoch 00018: val_acc improved from 0.78802 to 0.80184, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.6113 - acc: 0.7241 - val_loss: 0.6117 - val_acc: 0.8018\n",
      "Epoch 20/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5942 - acc: 0.7532Epoch 00019: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.5964 - acc: 0.7504 - val_loss: 0.5835 - val_acc: 0.7679\n",
      "Epoch 21/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5494 - acc: 0.7786Epoch 00020: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.5533 - acc: 0.7774 - val_loss: 0.6405 - val_acc: 0.7788\n",
      "Epoch 22/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5539 - acc: 0.7722Epoch 00021: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.5532 - acc: 0.7722 - val_loss: 0.6847 - val_acc: 0.7723\n",
      "Epoch 23/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5758 - acc: 0.7595Epoch 00022: val_acc improved from 0.80184 to 0.82028, saving model to cars_classification_best.hdf5\n",
      "19/19 [==============================] - 21s - loss: 0.5769 - acc: 0.7609 - val_loss: 0.5397 - val_acc: 0.8203\n",
      "Epoch 24/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5623 - acc: 0.7619Epoch 00023: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.5771 - acc: 0.7556 - val_loss: 0.5769 - val_acc: 0.7902\n",
      "Epoch 25/25\n",
      "18/19 [===========================>..] - ETA: 0s - loss: 0.5281 - acc: 0.7714Epoch 00024: val_acc did not improve\n",
      "19/19 [==============================] - 20s - loss: 0.5291 - acc: 0.7707 - val_loss: 0.5188 - val_acc: 0.7788\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "minibatch_size = 70\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "checkpoint = ModelCheckpoint('cars_classification_best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# fine-tune the model\n",
    "history = new_model.fit_generator(\n",
    "    image_generator(train_indices, minibatch_size),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=image_generator(test_indices, minibatch_size),\n",
    "    nb_val_samples=test_steps,\n",
    "    callbacks=[checkpoint])\n",
    "# new_model.save('cars_classification_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIkKBLyISEQp8EZGIUOCLiETE/wfwP7CVfNd6xgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f962371e668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('../datasets/cars_classification_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    data = preprocess_input(data)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 20 + 20\n",
    "    predicted_label.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.85      0.97      0.90        29\n",
      "         20       0.87      0.94      0.91        36\n",
      "         40       0.76      0.82      0.79        34\n",
      "         60       0.81      0.52      0.63        25\n",
      "         80       0.82      0.78      0.80        23\n",
      "\n",
      "avg / total       0.82      0.82      0.82       147\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[28  0  0  0  1]\n",
      " [ 0 34  2  0  0]\n",
      " [ 0  3 28  2  1]\n",
      " [ 2  1  7 13  2]\n",
      " [ 3  1  0  1 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
