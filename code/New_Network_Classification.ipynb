{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"bikes_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        label = row[3]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))\n",
    "\n",
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 4))\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 4))\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)                \n",
    "                p = prices[index]\n",
    "                if p == \"25\":\n",
    "                    Y[i,:] = np.array([1,0,0,0])\n",
    "                if p == \"50\":\n",
    "                    Y[i,:] = np.array([0,1,0,0])\n",
    "                if p == \"75\":\n",
    "                    Y[i,:] = np.array([0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "num_settings = 1\n",
    "\n",
    "hp_dropout = [0.2] * num_settings\n",
    "\n",
    "#RMSprop\n",
    "hp_lr = [0.0001] * num_settings\n",
    "hp_rho = [0.9] * num_settings\n",
    "hp_epsilon = [1e-07] * num_settings\n",
    "hp_decay = [0.0] * num_settings\n",
    "\n",
    "# Number of hidden units\n",
    "hp_hidden = [300] * num_settings\n",
    "\n",
    "# Minibatch size\n",
    "hp_mbsize = [64] * num_settings\n",
    "minibatch_size = hp_mbsize[0]\n",
    "\n",
    "train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 224, 224, 56)      4256      \n",
      "_________________________________________________________________\n",
      "intermed (Conv2D)            (None, 224, 224, 56)      28280     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 56)      0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 112, 112, 56)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 112, 112, 64)      57408     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 28, 28, 40)        81960     \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 9, 9, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3240)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3240)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               829696    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 1,142,276\n",
      "Trainable params: 1,142,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=308, epochs=20, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=35)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "308/308 [==============================] - 341s - loss: 1.7401 - acc: 0.4140 - val_loss: 0.9668 - val_acc: 0.5767\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 330s - loss: 0.9594 - acc: 0.5612 - val_loss: 0.8697 - val_acc: 0.6189\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 329s - loss: 0.8659 - acc: 0.6122 - val_loss: 0.8040 - val_acc: 0.6487\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 330s - loss: 0.8035 - acc: 0.6437 - val_loss: 0.7604 - val_acc: 0.6740\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 329s - loss: 0.7486 - acc: 0.6657 - val_loss: 0.7302 - val_acc: 0.6865\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 329s - loss: 0.7043 - acc: 0.6920 - val_loss: 0.6847 - val_acc: 0.7132\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 329s - loss: 0.6649 - acc: 0.7090 - val_loss: 0.6675 - val_acc: 0.7123\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 329s - loss: 0.6279 - acc: 0.7276 - val_loss: 0.6492 - val_acc: 0.7203\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 329s - loss: 0.5874 - acc: 0.7479 - val_loss: 0.6129 - val_acc: 0.7363\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 330s - loss: 0.5590 - acc: 0.7594 - val_loss: 0.5984 - val_acc: 0.7434\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 329s - loss: 0.5241 - acc: 0.7771 - val_loss: 0.5887 - val_acc: 0.7568\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 329s - loss: 0.4995 - acc: 0.7907 - val_loss: 0.5640 - val_acc: 0.7563\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 329s - loss: 0.4727 - acc: 0.7996 - val_loss: 0.5525 - val_acc: 0.7675\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 329s - loss: 0.4448 - acc: 0.8138 - val_loss: 0.5466 - val_acc: 0.7781\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 329s - loss: 0.4185 - acc: 0.8248 - val_loss: 0.5255 - val_acc: 0.7870\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 329s - loss: 0.3966 - acc: 0.8343 - val_loss: 0.5401 - val_acc: 0.7906\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 329s - loss: 0.3806 - acc: 0.8422 - val_loss: 0.5473 - val_acc: 0.7924\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 329s - loss: 0.3531 - acc: 0.8549 - val_loss: 0.5428 - val_acc: 0.7955\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 329s - loss: 0.3396 - acc: 0.8621 - val_loss: 0.5441 - val_acc: 0.7932\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 329s - loss: 0.3221 - acc: 0.8716 - val_loss: 0.5342 - val_acc: 0.8017\n"
     ]
    }
   ],
   "source": [
    "# store the results of each setting\n",
    "train_losses = np.zeros(num_settings)\n",
    "dev_losses = np.zeros(num_settings)\n",
    "\n",
    "for setting in range(num_settings):\n",
    "\n",
    "    img_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # block 1\n",
    "    x = Conv2D(56, (5, 5), activation='relu', padding='same', kernel_initializer='glorot_normal', name='conv1')(img_input)\n",
    "    x = Conv2D(56, (3, 3), activation='relu', padding='same', kernel_initializer='glorot_normal', name='intermed')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # block 2\n",
    "    x = Dropout(hp_dropout[setting])(x)\n",
    "    x = Conv2D(64, (4, 4), activation='relu', padding='same', kernel_initializer='glorot_normal', name='conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "    # block 3\n",
    "    x = Dropout(hp_dropout[setting])(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='glorot_normal', name='conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    # block 4\n",
    "    x = Dropout(hp_dropout[setting])(x)\n",
    "    x = Conv2D(40, (4, 4), activation='relu', padding='same', kernel_initializer='glorot_normal', name='conv4')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(3, 3), name='pool4')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dropout(hp_dropout[setting])(x)\n",
    "    x = Dense(256, activation='relu', name='fc1', kernel_initializer='glorot_normal')(x)\n",
    "    x = Dense(256, activation='relu', name='fc2', kernel_initializer='glorot_normal')(x)\n",
    "    x = Dense(4, activation='softmax', name='output', kernel_initializer='glorot_normal')(x)\n",
    "    \n",
    "    new_model = Model(img_input, x, name='new_network_classification')\n",
    "    \n",
    "    print(new_model.summary())\n",
    "    \n",
    "    # Adam optimizer\n",
    "    new_model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.Adam(\n",
    "                              lr=hp_lr[setting],\n",
    "                              decay=hp_decay[setting]),\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint_path = '/output/new-network-classification-best.hdf5'\n",
    "    \n",
    "    # keep a checkpoint\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                                monitor='val_acc',\n",
    "                                save_best_only=True,\n",
    "                                mode='max')\n",
    "\n",
    "    minibatch_size = hp_mbsize[setting]\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(train_indices, minibatch_size),\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        nb_val_samples=test_steps,\n",
    "        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions on each batch yielded the validation generator.\n",
    "\n",
    "new_model = load_model('/output/new-network-classification-best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    data = preprocess_input(data)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 25 + 25\n",
    "    predicted_label.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.86      0.79      0.83       496\n",
      "         25       0.92      0.82      0.87       596\n",
      "         50       0.75      0.80      0.77       563\n",
      "         75       0.71      0.80      0.75       530\n",
      "\n",
      "avg / total       0.81      0.80      0.80      2185\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[394   2   2  98]\n",
      " [  1 489  97   9]\n",
      " [  8  38 448  69]\n",
      " [ 53   4  51 422]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
