{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"../datasets/bikes_filtered.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(int(msrp))\n",
    "\n",
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a data point and run it through the neural network\n",
    "# Return the predicted value and calculate the MSE\n",
    "def evaluate(model, index):\n",
    "    msrp = prices[index]\n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    # TODO: the input should be preprocessed before feeding it in\n",
    "    prediction = model.predict(data, msrp)\n",
    "    \n",
    "    #print(\"Bike index: \" + str(index))\n",
    "    #print(\"Actual price: \" + str(msrp))\n",
    "    #print(\"Predicted price: \" + str(prediction))\n",
    "    mse = (prediction-msrp)**2\n",
    "    return mse\n",
    "\n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 1))\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 1))\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)                \n",
    "                Y[i] = prices[index]\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "num_settings = 7\n",
    "\n",
    "hp_dropout = [0.2] * num_settings\n",
    "\n",
    "#RMSprop\n",
    "hp_lr = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "hp_rho = [0.9] * num_settings\n",
    "hp_epsilon = [1e-07] * num_settings\n",
    "hp_decay = [0.0] * num_settings\n",
    "\n",
    "# Number of hidden units\n",
    "hp_hidden = [256] * num_settings\n",
    "\n",
    "# Minibatch size\n",
    "hp_mbsize = [64] * num_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=352, epochs=10, validation_data=<generator..., validation_steps=40)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "350/352 [============================>.] - ETA: 1s - loss: 1992878.8196"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[58,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_463 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_533_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'block1_conv2_1/convolution', defined at:\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-50c887e778c4>\", line 12, in <module>\n    model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 113, in VGG16\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3189, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 672, in convolution\n    op=op)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 664, in op\n    name=name)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 397, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[58,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_463 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_533_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[58,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_463 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_533_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-50c887e778c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         nb_val_samples=test_steps)\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# TODO: we should consider the validation loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2134\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2135\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2136\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1832\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[58,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_463 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_533_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'block1_conv2_1/convolution', defined at:\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-50c887e778c4>\", line 12, in <module>\n    model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 113, in VGG16\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3189, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 672, in convolution\n    op=op)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 338, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 664, in op\n    name=name)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 131, in _non_atrous_convolution\n    name=name)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 397, in conv2d\n    data_format=data_format, name=name)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\stevenzc\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[58,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_463 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_533_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Each index in the list corresponds to a HP setting\n",
    "# E.G. setting = 1 will select dropout = 0.01, lr = 0.01, rho = 0.9 ...\n",
    "# TODO: vary the settings, right now I only vary dropout and clamp all the others to a single value\n",
    "\n",
    "# store the results of each setting\n",
    "train_losses = np.zeros(num_settings)\n",
    "dev_losses = np.zeros(num_settings)\n",
    "\n",
    "for setting in range(num_settings):\n",
    "    # build the VGG16 network\n",
    "    input_tensor = Input(shape=(224,224,3))\n",
    "    model = applications.VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=(model.output_shape[1:])))\n",
    "\n",
    "\n",
    "    # Output layer\n",
    "    # We do random weight intialization\n",
    "    top_model.add(Dropout(hp_dropout[setting]))\n",
    "    top_model.add(Dense(hp_hidden[setting], activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    top_model.add(Dense(1, activation='linear', name='output', kernel_initializer='glorot_uniform'))\n",
    "    \n",
    "    # add the model on top of the convolutional base\n",
    "    new_model = Model(inputs= model.input, outputs = top_model(model.output))\n",
    "\n",
    "    # set the first 19 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in new_model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # RMSprop\n",
    "    new_model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizers.RMSprop(\n",
    "                              lr=hp_lr[setting], \n",
    "                              rho=hp_rho[setting], \n",
    "                              epsilon=hp_epsilon[setting], \n",
    "                              decay=hp_decay[setting]))\n",
    "    \n",
    "    epochs = 10\n",
    "    minibatch_size = hp_mbsize[setting]\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(train_indices, minibatch_size),\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        nb_val_samples=test_steps)\n",
    "    \n",
    "    # TODO: we should consider the validation loss\n",
    "    #error = []\n",
    "    #for i in range(21843):\n",
    "    #    error.append(evaluate(new_model,i))\n",
    "    \n",
    "    # store the training and dev losses for the last epoch (current model)\n",
    "    train_losses[setting] = history.history['loss'][-1]\n",
    "    dev_losses[setting] = history.history['val_loss'][-1]\n",
    "    \n",
    "    print(np.mean(error))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
