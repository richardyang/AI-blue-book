{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19658,)\n",
      "(2185,)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dropout, Concatenate, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/wohlert/keras-squeezenet/releases/download/v0.1/squeezenet_weights.h5'\n",
    "\n",
    "def _fire(x, filters, name=\"fire\"):\n",
    "    sq_filters, ex1_filters, ex2_filters = filters\n",
    "    squeeze = Convolution2D(sq_filters, (1, 1), activation='relu', padding='same', name=name + \"squeeze1x1\")(x)\n",
    "    expand1 = Convolution2D(ex1_filters, (1, 1), activation='relu', padding='same', name=name + \"expand1x1\")(squeeze)\n",
    "    expand2 = Convolution2D(ex2_filters, (3, 3), activation='relu', padding='same', name=name + \"expand3x3\")(squeeze)\n",
    "    x = Concatenate(axis=-1, name=name)([expand1, expand2])\n",
    "    return x\n",
    "\n",
    "def SqueezeNet(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=1000):\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = Convolution2D(64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\", name='conv1')(img_input)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (16, 64, 64), name=\"fire2\")\n",
    "    y = _fire(x, (16, 64, 64), name=\"fire3\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool3', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (32, 128, 128), name=\"fire4\")\n",
    "    y = _fire(x, (32, 128, 128), name=\"fire5\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)   \n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool5', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (48, 192, 192), name=\"fire6\")\n",
    "    y = _fire(x, (48, 192, 192), name=\"fire7\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = _fire(x, (64, 256, 256), name=\"fire8\")\n",
    "    y = _fire(x, (64, 256, 256), name=\"fire9\")\n",
    "    \n",
    "    x = keras.layers.add([x,y])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dropout(0.5, name='dropout9')(x)\n",
    "\n",
    "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "        x = AveragePooling2D(pool_size=(13, 13), name='avgpool10')(x)\n",
    "        x = Flatten(name='flatten10')(x)\n",
    "        x = Activation(\"softmax\", name='softmax')(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = GlobalAveragePooling2D(name=\"avgpool10\")(x)\n",
    "        else:\n",
    "            x = GlobalMaxPooling2D(name=\"maxpool10\")(x)\n",
    "\n",
    "    model = Model(img_input, x, name=\"squeezenet\")\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        weights_path = get_file('squeezenet_weights.h5',\n",
    "                                WEIGHTS_PATH,\n",
    "                                cache_subdir='models')\n",
    "\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# read the CSV into memory\n",
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../datasets/bikes_im/\"\n",
    "with open(\"../datasets/bikes_classified.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        name = row[1]\n",
    "        msrp = row[2]\n",
    "        label = row[3]\n",
    "        \n",
    "        image_path = data_path + index + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(str(label))\n",
    "        \n",
    "train_indices = np.load(\"bikes_train_indices.npy\")\n",
    "test_indices = np.load(\"bikes_test_indices.npy\")\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "])\n",
    "\n",
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 4)) # Change to one-hot\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 4)) # Change to one-hot\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)\n",
    "                # Convert to 1 hot vector\n",
    "                p = prices[index]\n",
    "                if p == \"25\":\n",
    "                    Y[i,:] = np.array([1,0,0,0])\n",
    "                if p == \"50\":\n",
    "                    Y[i,:] = np.array([0,1,0,0])\n",
    "                if p == \"75\":\n",
    "                    Y[i,:] = np.array([0,0,1,0])\n",
    "                if p == \"100\":\n",
    "                    Y[i,:] = np.array([0,0,0,1])\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            X = seq.augment_images(X)\n",
    "            \n",
    "            yield (X, Y)\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_settings = 1\n",
    "\n",
    "hp_dropout = [0.5] * num_settings\n",
    "\n",
    "#RMSprop\n",
    "hp_lr = [0.005] * num_settings\n",
    "hp_rho = [0.9] * num_settings\n",
    "hp_epsilon = [1e-07] * num_settings\n",
    "hp_decay = [0.0] * num_settings\n",
    "\n",
    "# Number of hidden units\n",
    "hp_hidden = [256] * num_settings\n",
    "\n",
    "# Minibatch size\n",
    "hp_mbsize = [256] * num_settings\n",
    "\n",
    "num_epochs = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 55, 55, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2squeeze1x1 (Conv2D)        (None, 55, 55, 16)   1040        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2expand1x1 (Conv2D)         (None, 55, 55, 64)   1088        fire2squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2expand3x3 (Conv2D)         (None, 55, 55, 64)   9280        fire2squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2 (Concatenate)             (None, 55, 55, 128)  0           fire2expand1x1[0][0]             \n",
      "                                                                 fire2expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire3squeeze1x1 (Conv2D)        (None, 55, 55, 16)   2064        fire2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire3expand1x1 (Conv2D)         (None, 55, 55, 64)   1088        fire3squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3expand3x3 (Conv2D)         (None, 55, 55, 64)   9280        fire3squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3 (Concatenate)             (None, 55, 55, 128)  0           fire3expand1x1[0][0]             \n",
      "                                                                 fire3expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 55, 55, 128)  0           fire2[0][0]                      \n",
      "                                                                 fire3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)         (None, 27, 27, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4squeeze1x1 (Conv2D)        (None, 27, 27, 32)   4128        maxpool3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire4expand1x1 (Conv2D)         (None, 27, 27, 128)  4224        fire4squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4expand3x3 (Conv2D)         (None, 27, 27, 128)  36992       fire4squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4 (Concatenate)             (None, 27, 27, 256)  0           fire4expand1x1[0][0]             \n",
      "                                                                 fire4expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire5squeeze1x1 (Conv2D)        (None, 27, 27, 32)   8224        fire4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire5expand1x1 (Conv2D)         (None, 27, 27, 128)  4224        fire5squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5expand3x3 (Conv2D)         (None, 27, 27, 128)  36992       fire5squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5 (Concatenate)             (None, 27, 27, 256)  0           fire5expand1x1[0][0]             \n",
      "                                                                 fire5expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 27, 27, 256)  0           fire4[0][0]                      \n",
      "                                                                 fire5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 27, 27, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool5 (MaxPooling2D)         (None, 13, 13, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fire6squeeze1x1 (Conv2D)        (None, 13, 13, 48)   12336       maxpool5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire6expand1x1 (Conv2D)         (None, 13, 13, 192)  9408        fire6squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6expand3x3 (Conv2D)         (None, 13, 13, 192)  83136       fire6squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6 (Concatenate)             (None, 13, 13, 384)  0           fire6expand1x1[0][0]             \n",
      "                                                                 fire6expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire7squeeze1x1 (Conv2D)        (None, 13, 13, 48)   18480       fire6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire7expand1x1 (Conv2D)         (None, 13, 13, 192)  9408        fire7squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7expand3x3 (Conv2D)         (None, 13, 13, 192)  83136       fire7squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7 (Concatenate)             (None, 13, 13, 384)  0           fire7expand1x1[0][0]             \n",
      "                                                                 fire7expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 13, 13, 384)  0           fire6[0][0]                      \n",
      "                                                                 fire7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 13, 384)  1536        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "fire8squeeze1x1 (Conv2D)        (None, 13, 13, 64)   24640       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fire8expand1x1 (Conv2D)         (None, 13, 13, 256)  16640       fire8squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8expand3x3 (Conv2D)         (None, 13, 13, 256)  147712      fire8squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8 (Concatenate)             (None, 13, 13, 512)  0           fire8expand1x1[0][0]             \n",
      "                                                                 fire8expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fire9squeeze1x1 (Conv2D)        (None, 13, 13, 64)   32832       fire8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire9expand1x1 (Conv2D)         (None, 13, 13, 256)  16640       fire9squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9expand3x3 (Conv2D)         (None, 13, 13, 256)  147712      fire9squeeze1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9 (Concatenate)             (None, 13, 13, 512)  0           fire9expand1x1[0][0]             \n",
      "                                                                 fire9expand3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 13, 13, 512)  0           fire8[0][0]                      \n",
      "                                                                 fire9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 13, 13, 512)  2048        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 4)            394756      batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,122,372\n",
      "Trainable params: 1,119,812\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:48: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:48: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=77, epochs=500, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=9)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "77/77 [==============================] - 212s 3s/step - loss: 1.2623 - acc: 0.4095 - val_loss: 1.1606 - val_acc: 0.4568\n",
      "Epoch 2/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 1.0754 - acc: 0.5021 - val_loss: 1.1437 - val_acc: 0.4715\n",
      "Epoch 3/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.9957 - acc: 0.5431 - val_loss: 1.0637 - val_acc: 0.5252\n",
      "Epoch 4/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.9484 - acc: 0.5691 - val_loss: 0.9477 - val_acc: 0.5510\n",
      "Epoch 5/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.9017 - acc: 0.5883 - val_loss: 0.9707 - val_acc: 0.5686\n",
      "Epoch 6/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.8857 - acc: 0.5943 - val_loss: 0.9344 - val_acc: 0.5989\n",
      "Epoch 7/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.8483 - acc: 0.6158 - val_loss: 0.8997 - val_acc: 0.5944\n",
      "Epoch 8/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.8333 - acc: 0.6217 - val_loss: 0.8363 - val_acc: 0.6227\n",
      "Epoch 9/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.8072 - acc: 0.6338 - val_loss: 0.7989 - val_acc: 0.6465\n",
      "Epoch 10/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.7872 - acc: 0.6433 - val_loss: 0.8119 - val_acc: 0.6415\n",
      "Epoch 11/500\n",
      "77/77 [==============================] - 191s 2s/step - loss: 0.7699 - acc: 0.6525 - val_loss: 0.8291 - val_acc: 0.6350\n",
      "Epoch 12/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.7505 - acc: 0.6639 - val_loss: 0.7679 - val_acc: 0.6497\n",
      "Epoch 13/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.7379 - acc: 0.6617 - val_loss: 0.8009 - val_acc: 0.6465\n",
      "Epoch 14/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.7267 - acc: 0.6743 - val_loss: 0.7850 - val_acc: 0.6653\n",
      "Epoch 15/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.7164 - acc: 0.6757 - val_loss: 0.9559 - val_acc: 0.5735\n",
      "Epoch 16/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.7008 - acc: 0.6868 - val_loss: 0.7700 - val_acc: 0.6551\n",
      "Epoch 17/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.6916 - acc: 0.6923 - val_loss: 1.0514 - val_acc: 0.5404\n",
      "Epoch 18/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.6780 - acc: 0.6955 - val_loss: 0.8229 - val_acc: 0.6313\n",
      "Epoch 19/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.6813 - acc: 0.6931 - val_loss: 0.9076 - val_acc: 0.5780\n",
      "Epoch 20/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.6617 - acc: 0.7079 - val_loss: 0.6928 - val_acc: 0.6874\n",
      "Epoch 21/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.6565 - acc: 0.7092 - val_loss: 0.7490 - val_acc: 0.6706\n",
      "Epoch 22/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.6464 - acc: 0.7140 - val_loss: 0.7425 - val_acc: 0.6817\n",
      "Epoch 23/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.6418 - acc: 0.7149 - val_loss: 0.6953 - val_acc: 0.6805\n",
      "Epoch 24/500\n",
      "77/77 [==============================] - 191s 2s/step - loss: 0.6357 - acc: 0.7163 - val_loss: 0.7136 - val_acc: 0.6800\n",
      "Epoch 25/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.6239 - acc: 0.7200 - val_loss: 0.7492 - val_acc: 0.6628\n",
      "Epoch 26/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.6170 - acc: 0.7286 - val_loss: 0.7831 - val_acc: 0.6575\n",
      "Epoch 27/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.6135 - acc: 0.7341 - val_loss: 0.6726 - val_acc: 0.7038\n",
      "Epoch 28/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.6071 - acc: 0.7325 - val_loss: 0.6452 - val_acc: 0.7095\n",
      "Epoch 29/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.6025 - acc: 0.7323 - val_loss: 0.7528 - val_acc: 0.6723\n",
      "Epoch 30/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5992 - acc: 0.7336 - val_loss: 0.7910 - val_acc: 0.6583\n",
      "Epoch 31/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.5804 - acc: 0.7456 - val_loss: 0.9610 - val_acc: 0.5965\n",
      "Epoch 32/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5768 - acc: 0.7442 - val_loss: 0.6943 - val_acc: 0.6919\n",
      "Epoch 33/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.5755 - acc: 0.7448 - val_loss: 0.7220 - val_acc: 0.7075\n",
      "Epoch 34/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5767 - acc: 0.7427 - val_loss: 0.7916 - val_acc: 0.6424\n",
      "Epoch 35/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.5657 - acc: 0.7529 - val_loss: 0.7192 - val_acc: 0.6800\n",
      "Epoch 36/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5614 - acc: 0.7507 - val_loss: 0.9633 - val_acc: 0.6166\n",
      "Epoch 37/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.5530 - acc: 0.7575 - val_loss: 0.7419 - val_acc: 0.6862\n",
      "Epoch 38/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.5478 - acc: 0.7585 - val_loss: 0.6652 - val_acc: 0.7079\n",
      "Epoch 39/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.5408 - acc: 0.7638 - val_loss: 0.6475 - val_acc: 0.7120\n",
      "Epoch 40/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5449 - acc: 0.7651 - val_loss: 0.7833 - val_acc: 0.6583\n",
      "Epoch 41/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.5314 - acc: 0.7679 - val_loss: 0.7744 - val_acc: 0.6714\n",
      "Epoch 42/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.5362 - acc: 0.7643 - val_loss: 0.6796 - val_acc: 0.6997\n",
      "Epoch 43/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5280 - acc: 0.7707 - val_loss: 0.7336 - val_acc: 0.6821\n",
      "Epoch 44/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.5255 - acc: 0.7725 - val_loss: 0.6290 - val_acc: 0.7272\n",
      "Epoch 45/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.5130 - acc: 0.7783 - val_loss: 0.5893 - val_acc: 0.7399\n",
      "Epoch 46/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.5112 - acc: 0.7789 - val_loss: 0.6109 - val_acc: 0.7419\n",
      "Epoch 47/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.5084 - acc: 0.7808 - val_loss: 0.5896 - val_acc: 0.7460\n",
      "Epoch 48/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.5060 - acc: 0.7800 - val_loss: 1.0583 - val_acc: 0.5875\n",
      "Epoch 49/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.5074 - acc: 0.7843 - val_loss: 0.7975 - val_acc: 0.6489\n",
      "Epoch 50/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4970 - acc: 0.7829 - val_loss: 0.9337 - val_acc: 0.6293\n",
      "Epoch 51/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.4877 - acc: 0.7894 - val_loss: 0.6444 - val_acc: 0.7259\n",
      "Epoch 52/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.4896 - acc: 0.7887 - val_loss: 0.8029 - val_acc: 0.6710\n",
      "Epoch 53/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.4853 - acc: 0.7856 - val_loss: 0.5961 - val_acc: 0.7509\n",
      "Epoch 54/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4863 - acc: 0.7928 - val_loss: 0.5743 - val_acc: 0.7493\n",
      "Epoch 55/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.4761 - acc: 0.7972 - val_loss: 0.7266 - val_acc: 0.6907\n",
      "Epoch 56/500\n",
      "77/77 [==============================] - 191s 2s/step - loss: 0.4695 - acc: 0.7990 - val_loss: 0.6412 - val_acc: 0.7345\n",
      "Epoch 57/500\n",
      "77/77 [==============================] - 191s 2s/step - loss: 0.4719 - acc: 0.7967 - val_loss: 0.6038 - val_acc: 0.7341\n",
      "Epoch 58/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.4636 - acc: 0.8004 - val_loss: 0.7490 - val_acc: 0.7009\n",
      "Epoch 59/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4658 - acc: 0.7976 - val_loss: 0.6669 - val_acc: 0.7231\n",
      "Epoch 60/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.4622 - acc: 0.7999 - val_loss: 0.6681 - val_acc: 0.7280\n",
      "Epoch 61/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4584 - acc: 0.8009 - val_loss: 0.5916 - val_acc: 0.7419\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 188s 2s/step - loss: 0.4542 - acc: 0.8072 - val_loss: 0.7189 - val_acc: 0.7083\n",
      "Epoch 63/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.4469 - acc: 0.8084 - val_loss: 0.5810 - val_acc: 0.7579\n",
      "Epoch 64/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.4518 - acc: 0.8060 - val_loss: 0.7332 - val_acc: 0.7071\n",
      "Epoch 65/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.4435 - acc: 0.8139 - val_loss: 0.7622 - val_acc: 0.6932\n",
      "Epoch 66/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4397 - acc: 0.8098 - val_loss: 0.6070 - val_acc: 0.7571\n",
      "Epoch 67/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.4401 - acc: 0.8142 - val_loss: 0.5944 - val_acc: 0.7517\n",
      "Epoch 68/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.4358 - acc: 0.8139 - val_loss: 0.9630 - val_acc: 0.6583\n",
      "Epoch 69/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4343 - acc: 0.8145 - val_loss: 0.7957 - val_acc: 0.6821\n",
      "Epoch 70/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.4321 - acc: 0.8161 - val_loss: 0.7775 - val_acc: 0.6903\n",
      "Epoch 71/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.4250 - acc: 0.8191 - val_loss: 0.6940 - val_acc: 0.7210\n",
      "Epoch 72/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.4205 - acc: 0.8226 - val_loss: 0.5918 - val_acc: 0.7481\n",
      "Epoch 73/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.4191 - acc: 0.8244 - val_loss: 0.6672 - val_acc: 0.7194\n",
      "Epoch 74/500\n",
      "77/77 [==============================] - 180s 2s/step - loss: 0.4182 - acc: 0.8265 - val_loss: 0.6592 - val_acc: 0.7411\n",
      "Epoch 75/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.4113 - acc: 0.8259 - val_loss: 0.6302 - val_acc: 0.7370\n",
      "Epoch 76/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.4060 - acc: 0.8276 - val_loss: 0.9190 - val_acc: 0.6805\n",
      "Epoch 77/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.4082 - acc: 0.8271 - val_loss: 0.7090 - val_acc: 0.7304\n",
      "Epoch 78/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.4027 - acc: 0.8299 - val_loss: 0.6076 - val_acc: 0.7554\n",
      "Epoch 79/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.4008 - acc: 0.8315 - val_loss: 0.9783 - val_acc: 0.6501\n",
      "Epoch 80/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.3992 - acc: 0.8340 - val_loss: 0.7461 - val_acc: 0.7091\n",
      "Epoch 81/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3998 - acc: 0.8298 - val_loss: 0.6660 - val_acc: 0.7366\n",
      "Epoch 82/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3937 - acc: 0.8314 - val_loss: 0.6835 - val_acc: 0.7239\n",
      "Epoch 83/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3952 - acc: 0.8317 - val_loss: 0.8078 - val_acc: 0.6788\n",
      "Epoch 84/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3950 - acc: 0.8354 - val_loss: 0.6355 - val_acc: 0.7288\n",
      "Epoch 85/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3873 - acc: 0.8349 - val_loss: 0.6226 - val_acc: 0.7382\n",
      "Epoch 86/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3782 - acc: 0.8416 - val_loss: 0.6414 - val_acc: 0.7288\n",
      "Epoch 87/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3861 - acc: 0.8376 - val_loss: 0.7272 - val_acc: 0.7153\n",
      "Epoch 88/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3787 - acc: 0.8420 - val_loss: 0.6951 - val_acc: 0.7448\n",
      "Epoch 89/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3749 - acc: 0.8433 - val_loss: 0.6249 - val_acc: 0.7624\n",
      "Epoch 90/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3737 - acc: 0.8419 - val_loss: 0.6139 - val_acc: 0.7661\n",
      "Epoch 91/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.3701 - acc: 0.8452 - val_loss: 0.7211 - val_acc: 0.7206\n",
      "Epoch 92/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3696 - acc: 0.8461 - val_loss: 0.5844 - val_acc: 0.7603\n",
      "Epoch 93/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3698 - acc: 0.8444 - val_loss: 0.5543 - val_acc: 0.7866\n",
      "Epoch 94/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3712 - acc: 0.8469 - val_loss: 0.5858 - val_acc: 0.7747\n",
      "Epoch 95/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3660 - acc: 0.8463 - val_loss: 0.6576 - val_acc: 0.7501\n",
      "Epoch 96/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3609 - acc: 0.8504 - val_loss: 0.7864 - val_acc: 0.7116\n",
      "Epoch 97/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3628 - acc: 0.8473 - val_loss: 0.5863 - val_acc: 0.7694\n",
      "Epoch 98/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3558 - acc: 0.8522 - val_loss: 0.6868 - val_acc: 0.7571\n",
      "Epoch 99/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3519 - acc: 0.8529 - val_loss: 1.1774 - val_acc: 0.6088\n",
      "Epoch 100/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.3532 - acc: 0.8502 - val_loss: 0.6177 - val_acc: 0.7681\n",
      "Epoch 101/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3523 - acc: 0.8514 - val_loss: 0.5912 - val_acc: 0.7706\n",
      "Epoch 102/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3432 - acc: 0.8576 - val_loss: 0.8076 - val_acc: 0.7005\n",
      "Epoch 103/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3444 - acc: 0.8561 - val_loss: 0.7296 - val_acc: 0.7206\n",
      "Epoch 104/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3399 - acc: 0.8575 - val_loss: 0.6248 - val_acc: 0.7542\n",
      "Epoch 105/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3439 - acc: 0.8548 - val_loss: 0.7726 - val_acc: 0.7063\n",
      "Epoch 106/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3410 - acc: 0.8564 - val_loss: 0.8944 - val_acc: 0.6977\n",
      "Epoch 107/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3426 - acc: 0.8562 - val_loss: 0.8061 - val_acc: 0.6940\n",
      "Epoch 108/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.3366 - acc: 0.8597 - val_loss: 0.5688 - val_acc: 0.7685\n",
      "Epoch 109/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3262 - acc: 0.8640 - val_loss: 0.5891 - val_acc: 0.7685\n",
      "Epoch 110/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3314 - acc: 0.8617 - val_loss: 0.7530 - val_acc: 0.7083\n",
      "Epoch 111/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3301 - acc: 0.8653 - val_loss: 0.6936 - val_acc: 0.7177\n",
      "Epoch 112/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.3264 - acc: 0.8663 - val_loss: 0.7503 - val_acc: 0.7194\n",
      "Epoch 113/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3245 - acc: 0.8627 - val_loss: 0.5758 - val_acc: 0.7726\n",
      "Epoch 114/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3284 - acc: 0.8640 - val_loss: 0.5620 - val_acc: 0.7821\n",
      "Epoch 115/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3238 - acc: 0.8654 - val_loss: 0.6137 - val_acc: 0.7624\n",
      "Epoch 116/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3169 - acc: 0.8672 - val_loss: 0.5985 - val_acc: 0.7685\n",
      "Epoch 117/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3177 - acc: 0.8687 - val_loss: 0.5761 - val_acc: 0.7767\n",
      "Epoch 118/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.3215 - acc: 0.8663 - val_loss: 0.6888 - val_acc: 0.7366\n",
      "Epoch 119/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3095 - acc: 0.8725 - val_loss: 0.7155 - val_acc: 0.7202\n",
      "Epoch 120/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.3104 - acc: 0.8725 - val_loss: 0.6225 - val_acc: 0.7558\n",
      "Epoch 121/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3087 - acc: 0.8740 - val_loss: 0.5584 - val_acc: 0.7837\n",
      "Epoch 122/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3079 - acc: 0.8739 - val_loss: 0.7490 - val_acc: 0.7546\n",
      "Epoch 123/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 186s 2s/step - loss: 0.3043 - acc: 0.8753 - val_loss: 0.6611 - val_acc: 0.7501\n",
      "Epoch 124/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.3038 - acc: 0.8737 - val_loss: 0.6133 - val_acc: 0.7784\n",
      "Epoch 125/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2971 - acc: 0.8752 - val_loss: 0.5832 - val_acc: 0.7816\n",
      "Epoch 126/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2977 - acc: 0.8758 - val_loss: 0.9042 - val_acc: 0.6817\n",
      "Epoch 127/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2955 - acc: 0.8766 - val_loss: 0.5769 - val_acc: 0.7886\n",
      "Epoch 128/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2956 - acc: 0.8745 - val_loss: 0.5881 - val_acc: 0.7730\n",
      "Epoch 129/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2972 - acc: 0.8802 - val_loss: 0.8118 - val_acc: 0.7046\n",
      "Epoch 130/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2892 - acc: 0.8797 - val_loss: 0.7738 - val_acc: 0.7427\n",
      "Epoch 131/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.2954 - acc: 0.8791 - val_loss: 0.6519 - val_acc: 0.7673\n",
      "Epoch 132/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2903 - acc: 0.8813 - val_loss: 0.6159 - val_acc: 0.7849\n",
      "Epoch 133/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2857 - acc: 0.8831 - val_loss: 0.6273 - val_acc: 0.7587\n",
      "Epoch 134/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2867 - acc: 0.8790 - val_loss: 0.6375 - val_acc: 0.7612\n",
      "Epoch 135/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2794 - acc: 0.8842 - val_loss: 0.7147 - val_acc: 0.7448\n",
      "Epoch 136/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2743 - acc: 0.8861 - val_loss: 0.7048 - val_acc: 0.7513\n",
      "Epoch 137/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2792 - acc: 0.8846 - val_loss: 0.6168 - val_acc: 0.7874\n",
      "Epoch 138/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2776 - acc: 0.8864 - val_loss: 0.6015 - val_acc: 0.7894\n",
      "Epoch 139/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2744 - acc: 0.8883 - val_loss: 0.8779 - val_acc: 0.7050\n",
      "Epoch 140/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.2764 - acc: 0.8858 - val_loss: 0.6706 - val_acc: 0.7546\n",
      "Epoch 141/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2723 - acc: 0.8876 - val_loss: 0.5791 - val_acc: 0.7919\n",
      "Epoch 142/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2745 - acc: 0.8876 - val_loss: 0.6150 - val_acc: 0.7943\n",
      "Epoch 143/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2698 - acc: 0.8880 - val_loss: 0.7020 - val_acc: 0.7509\n",
      "Epoch 144/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2662 - acc: 0.8913 - val_loss: 0.6968 - val_acc: 0.7726\n",
      "Epoch 145/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2638 - acc: 0.8904 - val_loss: 0.6483 - val_acc: 0.7776\n",
      "Epoch 146/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.2649 - acc: 0.8898 - val_loss: 0.7610 - val_acc: 0.7497\n",
      "Epoch 147/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2623 - acc: 0.8944 - val_loss: 0.6346 - val_acc: 0.7821\n",
      "Epoch 148/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2622 - acc: 0.8925 - val_loss: 0.7276 - val_acc: 0.7571\n",
      "Epoch 149/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2590 - acc: 0.8952 - val_loss: 0.7852 - val_acc: 0.7403\n",
      "Epoch 150/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2600 - acc: 0.8941 - val_loss: 0.6867 - val_acc: 0.7644\n",
      "Epoch 151/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2596 - acc: 0.8953 - val_loss: 0.7243 - val_acc: 0.7415\n",
      "Epoch 152/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.2561 - acc: 0.8965 - val_loss: 0.6740 - val_acc: 0.7702\n",
      "Epoch 153/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2560 - acc: 0.8936 - val_loss: 0.8728 - val_acc: 0.7325\n",
      "Epoch 154/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2607 - acc: 0.8927 - val_loss: 0.6327 - val_acc: 0.7710\n",
      "Epoch 155/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.2532 - acc: 0.8947 - val_loss: 0.6964 - val_acc: 0.7636\n",
      "Epoch 156/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2518 - acc: 0.8991 - val_loss: 0.6652 - val_acc: 0.7886\n",
      "Epoch 157/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2497 - acc: 0.8993 - val_loss: 0.6649 - val_acc: 0.7722\n",
      "Epoch 158/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2459 - acc: 0.9007 - val_loss: 0.6685 - val_acc: 0.7759\n",
      "Epoch 159/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2426 - acc: 0.9020 - val_loss: 0.7178 - val_acc: 0.7579\n",
      "Epoch 160/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2440 - acc: 0.9004 - val_loss: 0.6372 - val_acc: 0.7788\n",
      "Epoch 161/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2447 - acc: 0.9016 - val_loss: 0.6989 - val_acc: 0.7788\n",
      "Epoch 162/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2358 - acc: 0.9037 - val_loss: 0.6390 - val_acc: 0.7927\n",
      "Epoch 163/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2427 - acc: 0.9018 - val_loss: 0.9136 - val_acc: 0.7427\n",
      "Epoch 164/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2408 - acc: 0.9018 - val_loss: 0.9203 - val_acc: 0.7476\n",
      "Epoch 165/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2404 - acc: 0.9020 - val_loss: 0.6487 - val_acc: 0.7767\n",
      "Epoch 166/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2332 - acc: 0.9053 - val_loss: 0.9734 - val_acc: 0.7206\n",
      "Epoch 167/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2276 - acc: 0.9055 - val_loss: 0.8495 - val_acc: 0.7419\n",
      "Epoch 168/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.2400 - acc: 0.9029 - val_loss: 0.6905 - val_acc: 0.7722\n",
      "Epoch 169/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.2280 - acc: 0.9091 - val_loss: 0.6706 - val_acc: 0.7878\n",
      "Epoch 170/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2272 - acc: 0.9084 - val_loss: 0.6121 - val_acc: 0.7886\n",
      "Epoch 171/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2308 - acc: 0.9083 - val_loss: 0.7077 - val_acc: 0.7780\n",
      "Epoch 172/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.2283 - acc: 0.9090 - val_loss: 0.6875 - val_acc: 0.7763\n",
      "Epoch 173/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2253 - acc: 0.9079 - val_loss: 0.6668 - val_acc: 0.7898\n",
      "Epoch 174/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2315 - acc: 0.9062 - val_loss: 0.7227 - val_acc: 0.7714\n",
      "Epoch 175/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2251 - acc: 0.9094 - val_loss: 0.8027 - val_acc: 0.7632\n",
      "Epoch 176/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2221 - acc: 0.9122 - val_loss: 0.7921 - val_acc: 0.7653\n",
      "Epoch 177/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2228 - acc: 0.9091 - val_loss: 0.6083 - val_acc: 0.7927\n",
      "Epoch 178/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2273 - acc: 0.9061 - val_loss: 0.6595 - val_acc: 0.7898\n",
      "Epoch 179/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2200 - acc: 0.9103 - val_loss: 0.6837 - val_acc: 0.7821\n",
      "Epoch 180/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2207 - acc: 0.9100 - val_loss: 0.6736 - val_acc: 0.7710\n",
      "Epoch 181/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2209 - acc: 0.9089 - val_loss: 0.7233 - val_acc: 0.7595\n",
      "Epoch 182/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2247 - acc: 0.9102 - val_loss: 0.6371 - val_acc: 0.7866\n",
      "Epoch 183/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2097 - acc: 0.9177 - val_loss: 0.6572 - val_acc: 0.7829\n",
      "Epoch 184/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 186s 2s/step - loss: 0.2120 - acc: 0.9154 - val_loss: 0.6566 - val_acc: 0.7907\n",
      "Epoch 185/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2117 - acc: 0.9160 - val_loss: 0.6057 - val_acc: 0.7960\n",
      "Epoch 186/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2150 - acc: 0.9132 - val_loss: 0.7433 - val_acc: 0.7845\n",
      "Epoch 187/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2076 - acc: 0.9171 - val_loss: 0.7362 - val_acc: 0.7640\n",
      "Epoch 188/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.2099 - acc: 0.9160 - val_loss: 0.7141 - val_acc: 0.7739\n",
      "Epoch 189/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2183 - acc: 0.9108 - val_loss: 0.7311 - val_acc: 0.7681\n",
      "Epoch 190/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.2145 - acc: 0.9137 - val_loss: 0.7718 - val_acc: 0.7534\n",
      "Epoch 191/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2067 - acc: 0.9151 - val_loss: 0.7042 - val_acc: 0.7845\n",
      "Epoch 192/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.2077 - acc: 0.9189 - val_loss: 0.6357 - val_acc: 0.7874\n",
      "Epoch 193/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2162 - acc: 0.9122 - val_loss: 0.6334 - val_acc: 0.7886\n",
      "Epoch 194/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.2101 - acc: 0.9154 - val_loss: 0.6295 - val_acc: 0.7902\n",
      "Epoch 195/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2050 - acc: 0.9169 - val_loss: 0.6121 - val_acc: 0.7845\n",
      "Epoch 196/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.2067 - acc: 0.9176 - val_loss: 0.7192 - val_acc: 0.7661\n",
      "Epoch 197/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1992 - acc: 0.9197 - val_loss: 0.6870 - val_acc: 0.7931\n",
      "Epoch 198/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.2003 - acc: 0.9205 - val_loss: 0.6685 - val_acc: 0.7759\n",
      "Epoch 199/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1993 - acc: 0.9172 - val_loss: 0.7008 - val_acc: 0.7825\n",
      "Epoch 200/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2030 - acc: 0.9186 - val_loss: 0.8124 - val_acc: 0.7608\n",
      "Epoch 201/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1975 - acc: 0.9196 - val_loss: 0.6393 - val_acc: 0.7874\n",
      "Epoch 202/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.2060 - acc: 0.9169 - val_loss: 0.7921 - val_acc: 0.7706\n",
      "Epoch 203/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1915 - acc: 0.9243 - val_loss: 0.6278 - val_acc: 0.7943\n",
      "Epoch 204/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1907 - acc: 0.9237 - val_loss: 0.7104 - val_acc: 0.7919\n",
      "Epoch 205/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1887 - acc: 0.9234 - val_loss: 0.6478 - val_acc: 0.8058\n",
      "Epoch 206/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1920 - acc: 0.9212 - val_loss: 0.7286 - val_acc: 0.7902\n",
      "Epoch 207/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1908 - acc: 0.9245 - val_loss: 0.7725 - val_acc: 0.7608\n",
      "Epoch 208/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1929 - acc: 0.9240 - val_loss: 0.9538 - val_acc: 0.7263\n",
      "Epoch 209/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1876 - acc: 0.9267 - val_loss: 0.6068 - val_acc: 0.8054\n",
      "Epoch 210/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1868 - acc: 0.9252 - val_loss: 0.6317 - val_acc: 0.8054\n",
      "Epoch 211/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1809 - acc: 0.9285 - val_loss: 0.6602 - val_acc: 0.7984\n",
      "Epoch 212/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1924 - acc: 0.9214 - val_loss: 0.6829 - val_acc: 0.7866\n",
      "Epoch 213/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1890 - acc: 0.9231 - val_loss: 0.6682 - val_acc: 0.8070\n",
      "Epoch 214/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1825 - acc: 0.9271 - val_loss: 0.7891 - val_acc: 0.7444\n",
      "Epoch 215/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1831 - acc: 0.9279 - val_loss: 0.9878 - val_acc: 0.6981\n",
      "Epoch 216/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1823 - acc: 0.9263 - val_loss: 0.6321 - val_acc: 0.8083\n",
      "Epoch 217/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1812 - acc: 0.9288 - val_loss: 0.8389 - val_acc: 0.7509\n",
      "Epoch 218/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1763 - acc: 0.9304 - val_loss: 0.9971 - val_acc: 0.7308\n",
      "Epoch 219/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1827 - acc: 0.9272 - val_loss: 0.7477 - val_acc: 0.7796\n",
      "Epoch 220/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1756 - acc: 0.9302 - val_loss: 0.7051 - val_acc: 0.7923\n",
      "Epoch 221/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1800 - acc: 0.9290 - val_loss: 0.8242 - val_acc: 0.7767\n",
      "Epoch 222/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1763 - acc: 0.9312 - val_loss: 0.6422 - val_acc: 0.8075\n",
      "Epoch 223/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1817 - acc: 0.9276 - val_loss: 0.7294 - val_acc: 0.8046\n",
      "Epoch 224/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1764 - acc: 0.9287 - val_loss: 1.0447 - val_acc: 0.7296\n",
      "Epoch 225/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1739 - acc: 0.9302 - val_loss: 1.0249 - val_acc: 0.7325\n",
      "Epoch 226/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1736 - acc: 0.9306 - val_loss: 0.7645 - val_acc: 0.7939\n",
      "Epoch 227/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1699 - acc: 0.9318 - val_loss: 0.7919 - val_acc: 0.7792\n",
      "Epoch 228/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.1789 - acc: 0.9293 - val_loss: 0.7465 - val_acc: 0.7771\n",
      "Epoch 229/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1729 - acc: 0.9307 - val_loss: 0.6892 - val_acc: 0.8038\n",
      "Epoch 230/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1732 - acc: 0.9334 - val_loss: 0.8827 - val_acc: 0.7632\n",
      "Epoch 231/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1687 - acc: 0.9327 - val_loss: 0.8545 - val_acc: 0.7751\n",
      "Epoch 232/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1674 - acc: 0.9347 - val_loss: 1.4980 - val_acc: 0.6473\n",
      "Epoch 233/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1669 - acc: 0.9352 - val_loss: 0.7570 - val_acc: 0.7980\n",
      "Epoch 234/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1735 - acc: 0.9329 - val_loss: 0.6728 - val_acc: 0.8038\n",
      "Epoch 235/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1663 - acc: 0.9348 - val_loss: 0.7931 - val_acc: 0.7739\n",
      "Epoch 236/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1628 - acc: 0.9363 - val_loss: 0.7221 - val_acc: 0.7849\n",
      "Epoch 237/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1660 - acc: 0.9335 - val_loss: 0.8965 - val_acc: 0.7485\n",
      "Epoch 238/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1647 - acc: 0.9336 - val_loss: 0.7150 - val_acc: 0.8075\n",
      "Epoch 239/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1653 - acc: 0.9356 - val_loss: 0.7655 - val_acc: 0.7898\n",
      "Epoch 240/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1627 - acc: 0.9369 - val_loss: 0.9445 - val_acc: 0.7685\n",
      "Epoch 241/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1584 - acc: 0.9359 - val_loss: 0.7227 - val_acc: 0.7997\n",
      "Epoch 242/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1577 - acc: 0.9381 - val_loss: 0.7003 - val_acc: 0.8029\n",
      "Epoch 243/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1582 - acc: 0.9376 - val_loss: 0.8124 - val_acc: 0.7776\n",
      "Epoch 244/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1557 - acc: 0.9392 - val_loss: 0.7783 - val_acc: 0.7808\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 185s 2s/step - loss: 0.1610 - acc: 0.9371 - val_loss: 0.9392 - val_acc: 0.7493\n",
      "Epoch 246/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1537 - acc: 0.9397 - val_loss: 0.8949 - val_acc: 0.7616\n",
      "Epoch 247/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1614 - acc: 0.9355 - val_loss: 0.8198 - val_acc: 0.7849\n",
      "Epoch 248/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1577 - acc: 0.9379 - val_loss: 0.7152 - val_acc: 0.8087\n",
      "Epoch 249/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1567 - acc: 0.9390 - val_loss: 0.9135 - val_acc: 0.7603\n",
      "Epoch 250/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1589 - acc: 0.9368 - val_loss: 0.7833 - val_acc: 0.7989\n",
      "Epoch 251/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.1597 - acc: 0.9373 - val_loss: 0.7993 - val_acc: 0.7915\n",
      "Epoch 252/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1553 - acc: 0.9383 - val_loss: 0.8764 - val_acc: 0.7685\n",
      "Epoch 253/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1556 - acc: 0.9378 - val_loss: 0.7652 - val_acc: 0.7980\n",
      "Epoch 254/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1565 - acc: 0.9398 - val_loss: 0.7216 - val_acc: 0.7968\n",
      "Epoch 255/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1565 - acc: 0.9383 - val_loss: 0.7094 - val_acc: 0.7931\n",
      "Epoch 256/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1538 - acc: 0.9390 - val_loss: 0.6964 - val_acc: 0.8009\n",
      "Epoch 257/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1538 - acc: 0.9396 - val_loss: 0.7424 - val_acc: 0.7948\n",
      "Epoch 258/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1536 - acc: 0.9401 - val_loss: 1.0033 - val_acc: 0.7505\n",
      "Epoch 259/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1458 - acc: 0.9417 - val_loss: 0.8012 - val_acc: 0.7952\n",
      "Epoch 260/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1524 - acc: 0.9410 - val_loss: 0.7221 - val_acc: 0.7919\n",
      "Epoch 261/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1504 - acc: 0.9411 - val_loss: 0.7315 - val_acc: 0.7915\n",
      "Epoch 262/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1482 - acc: 0.9404 - val_loss: 0.9991 - val_acc: 0.7526\n",
      "Epoch 263/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1504 - acc: 0.9412 - val_loss: 0.8191 - val_acc: 0.7812\n",
      "Epoch 264/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1490 - acc: 0.9410 - val_loss: 0.7452 - val_acc: 0.8001\n",
      "Epoch 265/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1482 - acc: 0.9413 - val_loss: 0.7785 - val_acc: 0.7857\n",
      "Epoch 266/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1423 - acc: 0.9437 - val_loss: 0.9626 - val_acc: 0.7550\n",
      "Epoch 267/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1510 - acc: 0.9420 - val_loss: 0.9075 - val_acc: 0.7698\n",
      "Epoch 268/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1438 - acc: 0.9434 - val_loss: 0.6911 - val_acc: 0.8005\n",
      "Epoch 269/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1437 - acc: 0.9450 - val_loss: 0.8462 - val_acc: 0.7644\n",
      "Epoch 270/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1402 - acc: 0.9461 - val_loss: 0.7114 - val_acc: 0.7915\n",
      "Epoch 271/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1474 - acc: 0.9431 - val_loss: 0.7180 - val_acc: 0.8005\n",
      "Epoch 272/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1404 - acc: 0.9461 - val_loss: 0.8181 - val_acc: 0.7673\n",
      "Epoch 273/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1431 - acc: 0.9422 - val_loss: 0.7068 - val_acc: 0.7989\n",
      "Epoch 274/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1383 - acc: 0.9459 - val_loss: 0.6948 - val_acc: 0.7952\n",
      "Epoch 275/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1402 - acc: 0.9448 - val_loss: 0.7645 - val_acc: 0.7948\n",
      "Epoch 276/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1358 - acc: 0.9466 - val_loss: 0.9455 - val_acc: 0.7464\n",
      "Epoch 277/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1424 - acc: 0.9433 - val_loss: 0.7201 - val_acc: 0.8124\n",
      "Epoch 278/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1376 - acc: 0.9473 - val_loss: 0.8268 - val_acc: 0.7882\n",
      "Epoch 279/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1374 - acc: 0.9475 - val_loss: 0.8226 - val_acc: 0.7907\n",
      "Epoch 280/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1379 - acc: 0.9467 - val_loss: 0.7596 - val_acc: 0.8046\n",
      "Epoch 281/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1351 - acc: 0.9494 - val_loss: 0.7099 - val_acc: 0.8021\n",
      "Epoch 282/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1392 - acc: 0.9466 - val_loss: 0.7268 - val_acc: 0.7870\n",
      "Epoch 283/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1332 - acc: 0.9487 - val_loss: 1.1009 - val_acc: 0.7403\n",
      "Epoch 284/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1345 - acc: 0.9494 - val_loss: 0.9210 - val_acc: 0.7780\n",
      "Epoch 285/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1325 - acc: 0.9483 - val_loss: 0.6935 - val_acc: 0.8124\n",
      "Epoch 286/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1362 - acc: 0.9471 - val_loss: 0.7583 - val_acc: 0.8066\n",
      "Epoch 287/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1344 - acc: 0.9483 - val_loss: 0.6933 - val_acc: 0.8206\n",
      "Epoch 288/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1315 - acc: 0.9496 - val_loss: 0.7002 - val_acc: 0.8070\n",
      "Epoch 289/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1275 - acc: 0.9503 - val_loss: 0.7339 - val_acc: 0.7997\n",
      "Epoch 290/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1296 - acc: 0.9497 - val_loss: 0.7036 - val_acc: 0.7968\n",
      "Epoch 291/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1340 - acc: 0.9485 - val_loss: 0.9563 - val_acc: 0.7644\n",
      "Epoch 292/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1285 - acc: 0.9517 - val_loss: 0.7192 - val_acc: 0.8095\n",
      "Epoch 293/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1316 - acc: 0.9502 - val_loss: 0.7981 - val_acc: 0.7943\n",
      "Epoch 294/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1315 - acc: 0.9471 - val_loss: 0.7541 - val_acc: 0.8038\n",
      "Epoch 295/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.1255 - acc: 0.9500 - val_loss: 1.0071 - val_acc: 0.7231\n",
      "Epoch 296/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1301 - acc: 0.9490 - val_loss: 0.7750 - val_acc: 0.8013\n",
      "Epoch 297/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.1266 - acc: 0.9506 - val_loss: 0.7683 - val_acc: 0.8079\n",
      "Epoch 298/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1222 - acc: 0.9528 - val_loss: 0.9047 - val_acc: 0.7882\n",
      "Epoch 299/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1297 - acc: 0.9495 - val_loss: 0.9199 - val_acc: 0.7554\n",
      "Epoch 300/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1287 - acc: 0.9514 - val_loss: 0.9235 - val_acc: 0.7726\n",
      "Epoch 301/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1228 - acc: 0.9518 - val_loss: 0.7647 - val_acc: 0.7984\n",
      "Epoch 302/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1228 - acc: 0.9516 - val_loss: 0.7799 - val_acc: 0.8054\n",
      "Epoch 303/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1253 - acc: 0.9502 - val_loss: 0.7427 - val_acc: 0.8148\n",
      "Epoch 304/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.1254 - acc: 0.9517 - val_loss: 0.8183 - val_acc: 0.7776\n",
      "Epoch 305/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1277 - acc: 0.9508 - val_loss: 0.8253 - val_acc: 0.8025\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 185s 2s/step - loss: 0.1280 - acc: 0.9502 - val_loss: 0.8342 - val_acc: 0.7886\n",
      "Epoch 307/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1249 - acc: 0.9521 - val_loss: 0.8423 - val_acc: 0.7849\n",
      "Epoch 308/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1261 - acc: 0.9514 - val_loss: 0.7727 - val_acc: 0.7845\n",
      "Epoch 309/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1239 - acc: 0.9522 - val_loss: 1.1706 - val_acc: 0.7349\n",
      "Epoch 310/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1288 - acc: 0.9500 - val_loss: 1.2773 - val_acc: 0.7083\n",
      "Epoch 311/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1246 - acc: 0.9524 - val_loss: 1.1713 - val_acc: 0.7263\n",
      "Epoch 312/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1178 - acc: 0.9553 - val_loss: 0.9871 - val_acc: 0.7534\n",
      "Epoch 313/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1227 - acc: 0.9531 - val_loss: 0.9473 - val_acc: 0.7685\n",
      "Epoch 314/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1276 - acc: 0.9509 - val_loss: 0.7379 - val_acc: 0.8083\n",
      "Epoch 315/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1250 - acc: 0.9524 - val_loss: 0.7619 - val_acc: 0.8034\n",
      "Epoch 316/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1196 - acc: 0.9552 - val_loss: 0.8262 - val_acc: 0.7993\n",
      "Epoch 317/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1204 - acc: 0.9522 - val_loss: 0.9033 - val_acc: 0.8001\n",
      "Epoch 318/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1184 - acc: 0.9530 - val_loss: 0.7406 - val_acc: 0.8120\n",
      "Epoch 319/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1230 - acc: 0.9524 - val_loss: 1.0253 - val_acc: 0.7763\n",
      "Epoch 320/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1160 - acc: 0.9552 - val_loss: 0.8934 - val_acc: 0.7833\n",
      "Epoch 321/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1208 - acc: 0.9522 - val_loss: 1.1149 - val_acc: 0.7407\n",
      "Epoch 322/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1147 - acc: 0.9561 - val_loss: 1.4525 - val_acc: 0.7001\n",
      "Epoch 323/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1177 - acc: 0.9557 - val_loss: 0.8211 - val_acc: 0.7808\n",
      "Epoch 324/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1178 - acc: 0.9535 - val_loss: 0.7275 - val_acc: 0.8128\n",
      "Epoch 325/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1129 - acc: 0.9555 - val_loss: 0.8855 - val_acc: 0.7804\n",
      "Epoch 326/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1145 - acc: 0.9557 - val_loss: 0.9904 - val_acc: 0.7710\n",
      "Epoch 327/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1197 - acc: 0.9527 - val_loss: 1.0763 - val_acc: 0.7681\n",
      "Epoch 328/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.1177 - acc: 0.9535 - val_loss: 0.8470 - val_acc: 0.8095\n",
      "Epoch 329/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1135 - acc: 0.9554 - val_loss: 0.9330 - val_acc: 0.7911\n",
      "Epoch 330/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1145 - acc: 0.9560 - val_loss: 0.8848 - val_acc: 0.8005\n",
      "Epoch 331/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1115 - acc: 0.9584 - val_loss: 0.8602 - val_acc: 0.7804\n",
      "Epoch 332/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1158 - acc: 0.9551 - val_loss: 0.7696 - val_acc: 0.8156\n",
      "Epoch 333/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1098 - acc: 0.9575 - val_loss: 0.7797 - val_acc: 0.8042\n",
      "Epoch 334/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1099 - acc: 0.9563 - val_loss: 0.8458 - val_acc: 0.7853\n",
      "Epoch 335/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1162 - acc: 0.9548 - val_loss: 0.7759 - val_acc: 0.7993\n",
      "Epoch 336/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1142 - acc: 0.9556 - val_loss: 0.7625 - val_acc: 0.7862\n",
      "Epoch 337/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1148 - acc: 0.9564 - val_loss: 0.8507 - val_acc: 0.8013\n",
      "Epoch 338/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1115 - acc: 0.9571 - val_loss: 0.9378 - val_acc: 0.7841\n",
      "Epoch 339/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1109 - acc: 0.9566 - val_loss: 0.8171 - val_acc: 0.8050\n",
      "Epoch 340/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.1075 - acc: 0.9591 - val_loss: 1.1981 - val_acc: 0.7493\n",
      "Epoch 341/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1065 - acc: 0.9583 - val_loss: 0.7889 - val_acc: 0.8050\n",
      "Epoch 342/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1157 - acc: 0.9560 - val_loss: 0.7642 - val_acc: 0.8087\n",
      "Epoch 343/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1119 - acc: 0.9570 - val_loss: 0.8520 - val_acc: 0.8066\n",
      "Epoch 344/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1087 - acc: 0.9597 - val_loss: 0.7785 - val_acc: 0.8079\n",
      "Epoch 345/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1111 - acc: 0.9578 - val_loss: 0.7538 - val_acc: 0.8066\n",
      "Epoch 346/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.1046 - acc: 0.9591 - val_loss: 0.8489 - val_acc: 0.7984\n",
      "Epoch 347/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1149 - acc: 0.9565 - val_loss: 0.7315 - val_acc: 0.8120\n",
      "Epoch 348/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1090 - acc: 0.9570 - val_loss: 0.8954 - val_acc: 0.7829\n",
      "Epoch 349/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1078 - acc: 0.9590 - val_loss: 0.8499 - val_acc: 0.7718\n",
      "Epoch 350/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1077 - acc: 0.9583 - val_loss: 0.7872 - val_acc: 0.8013\n",
      "Epoch 351/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1045 - acc: 0.9601 - val_loss: 0.7808 - val_acc: 0.8222\n",
      "Epoch 352/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1066 - acc: 0.9588 - val_loss: 0.9395 - val_acc: 0.7964\n",
      "Epoch 353/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.1086 - acc: 0.9586 - val_loss: 0.7611 - val_acc: 0.8263\n",
      "Epoch 354/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1072 - acc: 0.9585 - val_loss: 0.8120 - val_acc: 0.8050\n",
      "Epoch 355/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1024 - acc: 0.9617 - val_loss: 0.7607 - val_acc: 0.8042\n",
      "Epoch 356/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1066 - acc: 0.9592 - val_loss: 0.9512 - val_acc: 0.7886\n",
      "Epoch 357/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1067 - acc: 0.9590 - val_loss: 0.8496 - val_acc: 0.7800\n",
      "Epoch 358/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1016 - acc: 0.9611 - val_loss: 0.8479 - val_acc: 0.8218\n",
      "Epoch 359/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1063 - acc: 0.9594 - val_loss: 1.4499 - val_acc: 0.7181\n",
      "Epoch 360/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1043 - acc: 0.9601 - val_loss: 0.7598 - val_acc: 0.8189\n",
      "Epoch 361/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.1013 - acc: 0.9616 - val_loss: 0.8042 - val_acc: 0.8062\n",
      "Epoch 362/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1055 - acc: 0.9595 - val_loss: 0.8540 - val_acc: 0.8079\n",
      "Epoch 363/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1047 - acc: 0.9604 - val_loss: 0.8429 - val_acc: 0.8046\n",
      "Epoch 364/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.1016 - acc: 0.9601 - val_loss: 0.9337 - val_acc: 0.7804\n",
      "Epoch 365/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0995 - acc: 0.9628 - val_loss: 0.8995 - val_acc: 0.7907\n",
      "Epoch 366/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1014 - acc: 0.9605 - val_loss: 0.8936 - val_acc: 0.7599\n",
      "Epoch 367/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 184s 2s/step - loss: 0.0987 - acc: 0.9617 - val_loss: 0.7724 - val_acc: 0.8136\n",
      "Epoch 368/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0981 - acc: 0.9611 - val_loss: 0.8183 - val_acc: 0.8034\n",
      "Epoch 369/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1010 - acc: 0.9615 - val_loss: 0.7832 - val_acc: 0.8132\n",
      "Epoch 370/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0998 - acc: 0.9622 - val_loss: 0.9646 - val_acc: 0.8001\n",
      "Epoch 371/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.1016 - acc: 0.9610 - val_loss: 0.8084 - val_acc: 0.8152\n",
      "Epoch 372/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0973 - acc: 0.9623 - val_loss: 0.8031 - val_acc: 0.8091\n",
      "Epoch 373/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.1024 - acc: 0.9603 - val_loss: 0.7687 - val_acc: 0.8169\n",
      "Epoch 374/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0964 - acc: 0.9631 - val_loss: 0.8156 - val_acc: 0.8091\n",
      "Epoch 375/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0991 - acc: 0.9613 - val_loss: 0.7505 - val_acc: 0.8173\n",
      "Epoch 376/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0991 - acc: 0.9635 - val_loss: 1.0429 - val_acc: 0.7636\n",
      "Epoch 377/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0971 - acc: 0.9624 - val_loss: 1.1230 - val_acc: 0.7542\n",
      "Epoch 378/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0977 - acc: 0.9618 - val_loss: 0.8310 - val_acc: 0.8095\n",
      "Epoch 379/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.1011 - acc: 0.9607 - val_loss: 1.0937 - val_acc: 0.7751\n",
      "Epoch 380/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0983 - acc: 0.9630 - val_loss: 0.8731 - val_acc: 0.8050\n",
      "Epoch 381/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0959 - acc: 0.9632 - val_loss: 0.8764 - val_acc: 0.7984\n",
      "Epoch 382/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0964 - acc: 0.9622 - val_loss: 0.8926 - val_acc: 0.7956\n",
      "Epoch 383/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0954 - acc: 0.9626 - val_loss: 0.8683 - val_acc: 0.7939\n",
      "Epoch 384/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0907 - acc: 0.9657 - val_loss: 0.9003 - val_acc: 0.8099\n",
      "Epoch 385/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0950 - acc: 0.9644 - val_loss: 0.9385 - val_acc: 0.7767\n",
      "Epoch 386/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0980 - acc: 0.9612 - val_loss: 0.8031 - val_acc: 0.8091\n",
      "Epoch 387/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0944 - acc: 0.9649 - val_loss: 0.9894 - val_acc: 0.7808\n",
      "Epoch 388/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0957 - acc: 0.9652 - val_loss: 0.8137 - val_acc: 0.8185\n",
      "Epoch 389/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0974 - acc: 0.9638 - val_loss: 1.0254 - val_acc: 0.7841\n",
      "Epoch 390/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0953 - acc: 0.9639 - val_loss: 0.8045 - val_acc: 0.8124\n",
      "Epoch 391/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0936 - acc: 0.9651 - val_loss: 0.9241 - val_acc: 0.7939\n",
      "Epoch 392/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0990 - acc: 0.9622 - val_loss: 1.1960 - val_acc: 0.7550\n",
      "Epoch 393/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0987 - acc: 0.9626 - val_loss: 1.0632 - val_acc: 0.7743\n",
      "Epoch 394/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0976 - acc: 0.9618 - val_loss: 0.8768 - val_acc: 0.8111\n",
      "Epoch 395/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0905 - acc: 0.9661 - val_loss: 0.8227 - val_acc: 0.8243\n",
      "Epoch 396/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0904 - acc: 0.9655 - val_loss: 0.9989 - val_acc: 0.7894\n",
      "Epoch 397/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0903 - acc: 0.9672 - val_loss: 0.8792 - val_acc: 0.8214\n",
      "Epoch 398/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0918 - acc: 0.9656 - val_loss: 0.9208 - val_acc: 0.7935\n",
      "Epoch 399/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0922 - acc: 0.9652 - val_loss: 0.9232 - val_acc: 0.7841\n",
      "Epoch 400/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0927 - acc: 0.9646 - val_loss: 0.9390 - val_acc: 0.7997\n",
      "Epoch 401/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0945 - acc: 0.9644 - val_loss: 0.8475 - val_acc: 0.8210\n",
      "Epoch 402/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0904 - acc: 0.9663 - val_loss: 0.9084 - val_acc: 0.8132\n",
      "Epoch 403/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0896 - acc: 0.9657 - val_loss: 0.8650 - val_acc: 0.8124\n",
      "Epoch 404/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.0915 - acc: 0.9654 - val_loss: 0.9357 - val_acc: 0.8099\n",
      "Epoch 405/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0893 - acc: 0.9665 - val_loss: 0.8947 - val_acc: 0.8218\n",
      "Epoch 406/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0920 - acc: 0.9655 - val_loss: 0.9431 - val_acc: 0.8128\n",
      "Epoch 407/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0892 - acc: 0.9676 - val_loss: 0.8551 - val_acc: 0.8099\n",
      "Epoch 408/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0925 - acc: 0.9631 - val_loss: 0.8605 - val_acc: 0.8042\n",
      "Epoch 409/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0909 - acc: 0.9673 - val_loss: 1.2152 - val_acc: 0.7579\n",
      "Epoch 410/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0898 - acc: 0.9665 - val_loss: 0.9697 - val_acc: 0.7792\n",
      "Epoch 411/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0876 - acc: 0.9672 - val_loss: 0.8464 - val_acc: 0.8210\n",
      "Epoch 412/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.0884 - acc: 0.9651 - val_loss: 1.0630 - val_acc: 0.7894\n",
      "Epoch 413/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0860 - acc: 0.9665 - val_loss: 0.7955 - val_acc: 0.8247\n",
      "Epoch 414/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0935 - acc: 0.9653 - val_loss: 0.9879 - val_acc: 0.7943\n",
      "Epoch 415/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0874 - acc: 0.9662 - val_loss: 0.9999 - val_acc: 0.7677\n",
      "Epoch 416/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0876 - acc: 0.9657 - val_loss: 0.9533 - val_acc: 0.7980\n",
      "Epoch 417/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0879 - acc: 0.9665 - val_loss: 0.8282 - val_acc: 0.8103\n",
      "Epoch 418/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0883 - acc: 0.9658 - val_loss: 0.8269 - val_acc: 0.8165\n",
      "Epoch 419/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0872 - acc: 0.9670 - val_loss: 0.9127 - val_acc: 0.7952\n",
      "Epoch 420/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0889 - acc: 0.9660 - val_loss: 0.8600 - val_acc: 0.8001\n",
      "Epoch 421/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0861 - acc: 0.9670 - val_loss: 0.9557 - val_acc: 0.8046\n",
      "Epoch 422/500\n",
      "77/77 [==============================] - 190s 2s/step - loss: 0.0844 - acc: 0.9685 - val_loss: 0.8552 - val_acc: 0.8050\n",
      "Epoch 423/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0879 - acc: 0.9666 - val_loss: 1.1124 - val_acc: 0.7735\n",
      "Epoch 424/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0911 - acc: 0.9655 - val_loss: 0.7707 - val_acc: 0.8144\n",
      "Epoch 425/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0833 - acc: 0.9683 - val_loss: 1.0368 - val_acc: 0.7792\n",
      "Epoch 426/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0848 - acc: 0.9669 - val_loss: 0.7993 - val_acc: 0.8116\n",
      "Epoch 427/500\n",
      "77/77 [==============================] - 188s 2s/step - loss: 0.0841 - acc: 0.9667 - val_loss: 0.7819 - val_acc: 0.8124\n",
      "Epoch 428/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 187s 2s/step - loss: 0.0864 - acc: 0.9667 - val_loss: 1.2603 - val_acc: 0.7509\n",
      "Epoch 429/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0842 - acc: 0.9669 - val_loss: 0.7874 - val_acc: 0.8226\n",
      "Epoch 430/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0833 - acc: 0.9687 - val_loss: 0.8896 - val_acc: 0.8095\n",
      "Epoch 431/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0829 - acc: 0.9686 - val_loss: 0.9958 - val_acc: 0.7890\n",
      "Epoch 432/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0790 - acc: 0.9699 - val_loss: 0.9758 - val_acc: 0.7849\n",
      "Epoch 433/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0870 - acc: 0.9663 - val_loss: 0.8184 - val_acc: 0.8185\n",
      "Epoch 434/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0873 - acc: 0.9675 - val_loss: 0.8422 - val_acc: 0.8189\n",
      "Epoch 435/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0797 - acc: 0.9701 - val_loss: 0.8990 - val_acc: 0.8005\n",
      "Epoch 436/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0850 - acc: 0.9673 - val_loss: 0.9453 - val_acc: 0.7997\n",
      "Epoch 437/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0842 - acc: 0.9668 - val_loss: 0.8241 - val_acc: 0.7964\n",
      "Epoch 438/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0831 - acc: 0.9687 - val_loss: 0.9021 - val_acc: 0.7902\n",
      "Epoch 439/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0811 - acc: 0.9687 - val_loss: 0.8487 - val_acc: 0.8005\n",
      "Epoch 440/500\n",
      "77/77 [==============================] - 189s 2s/step - loss: 0.0791 - acc: 0.9686 - val_loss: 0.8759 - val_acc: 0.8099\n",
      "Epoch 441/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0866 - acc: 0.9666 - val_loss: 0.7430 - val_acc: 0.8238\n",
      "Epoch 442/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0780 - acc: 0.9713 - val_loss: 0.8361 - val_acc: 0.7984\n",
      "Epoch 443/500\n",
      "77/77 [==============================] - 183s 2s/step - loss: 0.0857 - acc: 0.9667 - val_loss: 0.8393 - val_acc: 0.8161\n",
      "Epoch 444/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0833 - acc: 0.9683 - val_loss: 0.9586 - val_acc: 0.7948\n",
      "Epoch 445/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0828 - acc: 0.9693 - val_loss: 0.8836 - val_acc: 0.8181\n",
      "Epoch 446/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0816 - acc: 0.9703 - val_loss: 0.7794 - val_acc: 0.8238\n",
      "Epoch 447/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0790 - acc: 0.9700 - val_loss: 0.8750 - val_acc: 0.8099\n",
      "Epoch 448/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0816 - acc: 0.9685 - val_loss: 0.9978 - val_acc: 0.7866\n",
      "Epoch 449/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0829 - acc: 0.9698 - val_loss: 0.8790 - val_acc: 0.8136\n",
      "Epoch 450/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0814 - acc: 0.9701 - val_loss: 0.8505 - val_acc: 0.8124\n",
      "Epoch 451/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0819 - acc: 0.9703 - val_loss: 1.2896 - val_acc: 0.7448\n",
      "Epoch 452/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0815 - acc: 0.9697 - val_loss: 1.0831 - val_acc: 0.7636\n",
      "Epoch 453/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0814 - acc: 0.9695 - val_loss: 1.0357 - val_acc: 0.7845\n",
      "Epoch 454/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0840 - acc: 0.9688 - val_loss: 0.9165 - val_acc: 0.8152\n",
      "Epoch 455/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0800 - acc: 0.9703 - val_loss: 0.9667 - val_acc: 0.7960\n",
      "Epoch 456/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0805 - acc: 0.9694 - val_loss: 0.9097 - val_acc: 0.7984\n",
      "Epoch 457/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0774 - acc: 0.9700 - val_loss: 1.0391 - val_acc: 0.7743\n",
      "Epoch 458/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0757 - acc: 0.9715 - val_loss: 1.0384 - val_acc: 0.7898\n",
      "Epoch 459/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0793 - acc: 0.9702 - val_loss: 0.9425 - val_acc: 0.8013\n",
      "Epoch 460/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0799 - acc: 0.9694 - val_loss: 1.0453 - val_acc: 0.7866\n",
      "Epoch 461/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0778 - acc: 0.9707 - val_loss: 0.9572 - val_acc: 0.7993\n",
      "Epoch 462/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0805 - acc: 0.9713 - val_loss: 0.7920 - val_acc: 0.8152\n",
      "Epoch 463/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0773 - acc: 0.9703 - val_loss: 0.8816 - val_acc: 0.8042\n",
      "Epoch 464/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0769 - acc: 0.9709 - val_loss: 1.1340 - val_acc: 0.7755\n",
      "Epoch 465/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0774 - acc: 0.9704 - val_loss: 0.8834 - val_acc: 0.8079\n",
      "Epoch 466/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0767 - acc: 0.9699 - val_loss: 1.2239 - val_acc: 0.7612\n",
      "Epoch 467/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0737 - acc: 0.9702 - val_loss: 0.7918 - val_acc: 0.8206\n",
      "Epoch 468/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0754 - acc: 0.9706 - val_loss: 0.8865 - val_acc: 0.8197\n",
      "Epoch 469/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0835 - acc: 0.9686 - val_loss: 0.8954 - val_acc: 0.8091\n",
      "Epoch 470/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0772 - acc: 0.9720 - val_loss: 1.2408 - val_acc: 0.7743\n",
      "Epoch 471/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0736 - acc: 0.9713 - val_loss: 1.1727 - val_acc: 0.7915\n",
      "Epoch 472/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0768 - acc: 0.9707 - val_loss: 0.8600 - val_acc: 0.8120\n",
      "Epoch 473/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0806 - acc: 0.9706 - val_loss: 0.9229 - val_acc: 0.8132\n",
      "Epoch 474/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0814 - acc: 0.9696 - val_loss: 0.8308 - val_acc: 0.8177\n",
      "Epoch 475/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0724 - acc: 0.9723 - val_loss: 1.0129 - val_acc: 0.8050\n",
      "Epoch 476/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0743 - acc: 0.9709 - val_loss: 1.1170 - val_acc: 0.7968\n",
      "Epoch 477/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0722 - acc: 0.9729 - val_loss: 1.0359 - val_acc: 0.8009\n",
      "Epoch 478/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0761 - acc: 0.9722 - val_loss: 0.9638 - val_acc: 0.8234\n",
      "Epoch 479/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0737 - acc: 0.9720 - val_loss: 0.9214 - val_acc: 0.8054\n",
      "Epoch 480/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0763 - acc: 0.9713 - val_loss: 1.0200 - val_acc: 0.7898\n",
      "Epoch 481/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0754 - acc: 0.9714 - val_loss: 0.9860 - val_acc: 0.8124\n",
      "Epoch 482/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0726 - acc: 0.9721 - val_loss: 0.9139 - val_acc: 0.8050\n",
      "Epoch 483/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0719 - acc: 0.9731 - val_loss: 0.9069 - val_acc: 0.7993\n",
      "Epoch 484/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0735 - acc: 0.9721 - val_loss: 1.0906 - val_acc: 0.7984\n",
      "Epoch 485/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0729 - acc: 0.9709 - val_loss: 1.0942 - val_acc: 0.7857\n",
      "Epoch 486/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0743 - acc: 0.9708 - val_loss: 1.1218 - val_acc: 0.7780\n",
      "Epoch 487/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0762 - acc: 0.9709 - val_loss: 0.8838 - val_acc: 0.8062\n",
      "Epoch 488/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0743 - acc: 0.9713 - val_loss: 1.0674 - val_acc: 0.7948\n",
      "Epoch 489/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 185s 2s/step - loss: 0.0703 - acc: 0.9743 - val_loss: 0.8280 - val_acc: 0.8152\n",
      "Epoch 490/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0737 - acc: 0.9731 - val_loss: 0.9435 - val_acc: 0.7976\n",
      "Epoch 491/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0740 - acc: 0.9725 - val_loss: 0.9369 - val_acc: 0.7898\n",
      "Epoch 492/500\n",
      "77/77 [==============================] - 187s 2s/step - loss: 0.0705 - acc: 0.9731 - val_loss: 0.9648 - val_acc: 0.8128\n",
      "Epoch 493/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0780 - acc: 0.9700 - val_loss: 0.9435 - val_acc: 0.8095\n",
      "Epoch 494/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0722 - acc: 0.9736 - val_loss: 1.2552 - val_acc: 0.7501\n",
      "Epoch 495/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0755 - acc: 0.9702 - val_loss: 1.0037 - val_acc: 0.7948\n",
      "Epoch 496/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0729 - acc: 0.9725 - val_loss: 0.9780 - val_acc: 0.7804\n",
      "Epoch 497/500\n",
      "77/77 [==============================] - 186s 2s/step - loss: 0.0728 - acc: 0.9738 - val_loss: 1.0489 - val_acc: 0.7890\n",
      "Epoch 498/500\n",
      "77/77 [==============================] - 184s 2s/step - loss: 0.0727 - acc: 0.9725 - val_loss: 1.0242 - val_acc: 0.7923\n",
      "Epoch 499/500\n",
      "77/77 [==============================] - 185s 2s/step - loss: 0.0738 - acc: 0.9723 - val_loss: 1.0068 - val_acc: 0.7898\n",
      "Epoch 500/500\n",
      "73/77 [===========================>..] - ETA: 8s - loss: 0.0682 - acc: 0.9743 "
     ]
    }
   ],
   "source": [
    "# store the results of each setting\n",
    "train_losses = np.zeros(num_settings)\n",
    "dev_losses = np.zeros(num_settings)\n",
    "\n",
    "for setting in range(num_settings):\n",
    "    model = SqueezeNet(include_top=True)\n",
    "    \n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Convolution2D(256, (1, 1), padding='valid', name='top_conv', input_shape=(model.layers[-1].output_shape[1:])))\n",
    "    top_model.add(AveragePooling2D(pool_size=(5, 5), name='top_avgpool'))\n",
    "    top_model.add(Flatten(input_shape=(model.layers[-1].output_shape[1:]),name='top_flatten'))\n",
    "    top_model.add(Dropout(hp_dropout[setting], name='top_dropout'))\n",
    "    top_model.add(Dense(hp_hidden[setting], activation='relu', kernel_initializer='glorot_uniform', name='top_dense'))\n",
    "    top_model.add(Dense(4, activation='softmax', name='output', kernel_initializer='glorot_uniform'))\n",
    "    \n",
    "    # add the model on top of the convolutional base\n",
    "    new_model = Model(inputs= model.input, outputs = top_model(model.layers[-1].output))\n",
    "    new_model.summary()\n",
    "\n",
    "    new_model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    checkpoint_path = 'output/bikes-cnn-PriceNet-Class-Aug/{epoch:05d}.hdf5'\n",
    "    \n",
    "    # keep a checkpoint\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, period=5)\n",
    "    \n",
    "    \n",
    "    minibatch_size = hp_mbsize[setting]\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit_generator(\n",
    "        image_generator(train_indices, minibatch_size),\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        nb_val_samples=test_steps,\n",
    "        callbacks=[checkpoint])\n",
    "    \n",
    "   \n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = []\n",
    "predicted_label = []\n",
    "for index in test_indices:\n",
    "    msrp = prices[index]\n",
    "    true_label.append(str(msrp))\n",
    "    \n",
    "    path = image_paths[index]\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    data = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "    \n",
    "    # Prediction outputs softmax vector\n",
    "    prediction = new_model.predict(data)\n",
    "    \n",
    "    # Set most confident prediction as label, and convert it to our price scale\n",
    "    label = np.argmax(prediction) * 25 + 25\n",
    "    predicted_label.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "      % (classification_report(true_label, predicted_label)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(true_label, predicted_label))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
